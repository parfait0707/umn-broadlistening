{
  "arguments": [
    {
      "arg_id": "A321_0",
      "argument": "AIは民主主義の原則に沿うべきだという要望がある",
      "x": -3.514204,
      "y": -2.4790845,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A321_1",
      "argument": "AIは西洋の民主主義ではなく、世界中の民主主義に沿うべきだという意見がある",
      "x": -3.3787873,
      "y": -2.5601242,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A341_0",
      "argument": "AIと環境に関する公共の認識、教育、参加を改善してほしいという要望がある",
      "x": -4.4948206,
      "y": -5.4865174,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A340_0",
      "argument": "AIシステムの利益とリスクを公平に分配してほしいという要望がある",
      "x": -5.042037,
      "y": -3.8543832,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_18"
      ]
    },
    {
      "arg_id": "A340_1",
      "argument": "AIシステムの利益とリスクが一部のグループに集中しないようにしてほしいという不安がある",
      "x": -0.8096124,
      "y": -3.4490016,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_21"
      ]
    },
    {
      "arg_id": "A339_0",
      "argument": "AIが人間の監視なしに重要な環境決定を自動化または制御すべきではないという意見がある",
      "x": -1.8618402,
      "y": -4.176585,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_15"
      ]
    },
    {
      "arg_id": "A337_0",
      "argument": "AIシステムは効率や利益だけでなく、正義、エンパワーメント、環境保護を促進すべきだという要望がある",
      "x": -5.4698997,
      "y": -4.4328566,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_12"
      ]
    },
    {
      "arg_id": "A336_0",
      "argument": "AIガバナンスの枠組みに環境代表者を含めるべきだという要望がある",
      "x": -2.4873405,
      "y": -4.9430037,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A336_1",
      "argument": "AIガバナンスが生態系への影響を考慮するべきだという意見がある",
      "x": -2.3148181,
      "y": -5.0464716,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A335_0",
      "argument": "AIを活用して人類の環境負荷を監視、モデル化し、最終的に削減することを求める要望がある",
      "x": -5.0735035,
      "y": -5.8170996,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A334_0",
      "argument": "AI研究者と開発者は、自分たちの仕事の環境への影響を考慮する倫理的責任があるという意見がある",
      "x": -3.5766144,
      "y": -4.039524,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A333_0",
      "argument": "AIシステムの環境負荷を理解するために包括的なライフサイクル評価を実施してほしいという要望がある",
      "x": -5.6870203,
      "y": -4.7383237,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_12"
      ]
    },
    {
      "arg_id": "A332_0",
      "argument": "AIシステムは持続可能性を考慮して設計・展開されるべきだという要望がある",
      "x": -5.641817,
      "y": -4.5154448,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_12"
      ]
    },
    {
      "arg_id": "A332_1",
      "argument": "AIシステムのエネルギー使用、材料、廃棄物などの環境影響を考慮してほしいという要望がある",
      "x": -5.6388583,
      "y": -4.814406,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_12"
      ]
    },
    {
      "arg_id": "A331_0",
      "argument": "AI開発はイノベーションを促進するべきだという要望がある",
      "x": -4.790582,
      "y": -4.4874544,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_8"
      ]
    },
    {
      "arg_id": "A331_1",
      "argument": "AIの利益が地理的または経済的な障壁に関係なく、すべての人にアクセス可能であるべきだという要望がある",
      "x": -4.3514175,
      "y": -4.2334995,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_8"
      ]
    },
    {
      "arg_id": "A330_0",
      "argument": "AI技術に対する包括的なリスク評価を行い、環境への影響だけでなく社会的・倫理的な影響も評価してほしいという要望がある",
      "x": -4.131123,
      "y": -4.236202,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_8"
      ]
    },
    {
      "arg_id": "A329_0",
      "argument": "AIシステムによる無許可のデータ収集と使用から個人を保護するために厳格なデータプライバシー規制が必要だという意見がある",
      "x": -1.7743294,
      "y": -2.81229,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_22"
      ]
    },
    {
      "arg_id": "A327_0",
      "argument": "AI技術が環境への影響を軽減するために、できるだけエネルギー効率を高めるべきだという要望がある",
      "x": -5.8014774,
      "y": -5.3086643,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_19"
      ]
    },
    {
      "arg_id": "A326_0",
      "argument": "グローバルスタンダードは理想的だが、文化や社会的な規範を尊重するローカライズされたAI規制が必要だという意見がある",
      "x": -1.4314986,
      "y": -3.0077007,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_22"
      ]
    },
    {
      "arg_id": "A325_0",
      "argument": "AI開発が人間の幸福と環境の持続可能性を優先する普遍的な倫理的枠組みに従うべきだという要望がある",
      "x": -3.8964918,
      "y": -4.083185,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A323_0",
      "argument": "AIの能力、限界、倫理的考慮について一般市民を教育するための取り組みを強化してほしいという要望がある",
      "x": -3.7758906,
      "y": -4.1319213,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A322_0",
      "argument": "AI開発に関わるすべての組織が使用する方法論とデータセットを公開してほしいという要望がある",
      "x": -4.571299,
      "y": -2.9276586,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_11"
      ]
    },
    {
      "arg_id": "A295_0",
      "argument": "政府はデータへのアクセスを拡大しながらプライバシーを保護する必要があるという要望がある",
      "x": -2.1406734,
      "y": -2.399728,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_22"
      ]
    },
    {
      "arg_id": "A320_0",
      "argument": "AIガバナンスにおけるグローバルな協力が環境変化の管理に重要であるという意見がある",
      "x": -2.2957933,
      "y": -4.8816147,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A319_0",
      "argument": "AIの導入が自然と人間の尊厳を尊重することを求める要望がある",
      "x": -3.8078196,
      "y": -3.553173,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A318_0",
      "argument": "AIの設計には持続可能な価値観を導入してほしいという要望がある",
      "x": -5.726506,
      "y": -4.805131,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_12"
      ]
    },
    {
      "arg_id": "A317_0",
      "argument": "AIの環境リスクを監視し、軽減する必要があるという意見がある",
      "x": -1.8725547,
      "y": -4.825015,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_15"
      ]
    },
    {
      "arg_id": "A317_1",
      "argument": "AIのエネルギー使用に対する不安がある",
      "x": -1.2758585,
      "y": -5.227863,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_14"
      ]
    },
    {
      "arg_id": "A317_2",
      "argument": "AIによる電子廃棄物に対する不安がある",
      "x": -1.3060483,
      "y": -5.134962,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_14"
      ]
    },
    {
      "arg_id": "A316_0",
      "argument": "ロボット工学と自動化が鉱業への影響を減らす可能性があるが、エネルギー需要が増加する可能性があることへの不安がある",
      "x": -1.3927125,
      "y": -5.3284845,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_14"
      ]
    },
    {
      "arg_id": "A316_1",
      "argument": "エネルギー需要の増加に対する計画が必要だという要望がある",
      "x": -5.6924014,
      "y": -4.9885445,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_12"
      ]
    },
    {
      "arg_id": "A300_0",
      "argument": "AIを公正、正義、人間の尊厳の原則に従って慎重に使用してほしいという要望がある",
      "x": -3.6746767,
      "y": -3.34605,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A297_0",
      "argument": "AIシステムへの攻撃を防ぐために、より強力なデジタルセキュリティが必要だという要望がある",
      "x": -5.491773,
      "y": -3.50416,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_18"
      ]
    },
    {
      "arg_id": "A294_0",
      "argument": "AIの利点とリスクは文脈によって異なるため、一律のガバナンスでは不十分だという意見がある",
      "x": -1.3405503,
      "y": -2.99604,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_22"
      ]
    },
    {
      "arg_id": "A293_0",
      "argument": "AIが人々の最善の利益に反して操作や誘導に使われるべきではないという意見がある",
      "x": -1.8622726,
      "y": -4.140385,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_15"
      ]
    },
    {
      "arg_id": "A292_0",
      "argument": "AIに対する規制の枠組みは、機敏で反復的かつ証拠に基づいたものであるべきだという要望がある",
      "x": -2.4496021,
      "y": -2.785732,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_23"
      ]
    },
    {
      "arg_id": "A291_0",
      "argument": "AIシステムによる被害が発生した場合の救済措置を導入してほしいという要望がある",
      "x": -5.702869,
      "y": -3.676699,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_18"
      ]
    },
    {
      "arg_id": "A288_0",
      "argument": "AIシステムが社会と相互作用する際の予期しない結果を継続的に再評価する必要があるという要望がある",
      "x": -5.4922886,
      "y": -3.9892268,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_18"
      ]
    },
    {
      "arg_id": "A287_0",
      "argument": "AI関係者が倫理的原則に従うために国際的な基準が必要だという要望がある",
      "x": -3.8524706,
      "y": -3.743207,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A286_0",
      "argument": "政府がデジタルインフラとAIスキルの訓練に投資して不平等を防ぐべきだという要望がある",
      "x": -2.6941109,
      "y": -2.7060494,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_23"
      ]
    },
    {
      "arg_id": "A284_0",
      "argument": "AIシステムによるプライバシーリスクを評価し、適切に軽減してほしいという要望がある",
      "x": -5.266702,
      "y": -3.626818,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_18"
      ]
    },
    {
      "arg_id": "A283_0",
      "argument": "自律型兵器システムにおいて、人間が制御を維持し、AIに致命的な決定を委ねないようにしてほしいという要望がある",
      "x": -3.4481468,
      "y": -3.451121,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A282_0",
      "argument": "AIを人権法と価値に従って開発・適用してほしいという要望がある",
      "x": -3.8234544,
      "y": -3.2400787,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A281_0",
      "argument": "アルゴリズムの公平性を確保してほしいという要望がある",
      "x": -4.276025,
      "y": -3.2611818,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_11"
      ]
    },
    {
      "arg_id": "A281_1",
      "argument": "アルゴリズムの説明責任を果たしてほしいという要望がある",
      "x": -4.233631,
      "y": -3.2614112,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_11"
      ]
    },
    {
      "arg_id": "A281_2",
      "argument": "アルゴリズムの透明性を高めてほしいという要望がある",
      "x": -4.3651214,
      "y": -3.1627328,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_11"
      ]
    },
    {
      "arg_id": "A281_3",
      "argument": "AIシステムに対する公共の信頼を築くためにこれらの要素が必要だという意見がある",
      "x": -5.354267,
      "y": -3.560307,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_18"
      ]
    },
    {
      "arg_id": "A280_0",
      "argument": "企業、国、政府が消費者やエンドユーザーに対してもっと教育や情報提供を行うべきだという要望がある",
      "x": -3.413445,
      "y": -3.886828,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A279_0",
      "argument": "企業や国がAI競争に集中しているが、社会的影響を適切に考慮していないことへの不満がある",
      "x": -0.78106743,
      "y": -3.8561494,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_21"
      ]
    },
    {
      "arg_id": "A279_1",
      "argument": "政府がAIに対する保護を行っていないことへの不満がある",
      "x": -1.1228737,
      "y": -3.715938,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_21"
      ]
    },
    {
      "arg_id": "A278_0",
      "argument": "AIが偏見を持つことへの不満がある",
      "x": -0.6687638,
      "y": -4.4729257,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A278_1",
      "argument": "AIの訓練データが既存の偏見を指摘しているため、根本的な問題を解決すべきだという意見がある",
      "x": -0.7306696,
      "y": -4.5756207,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A277_0",
      "argument": "新規参入者、製品、サービスにおけるAIインシデントの再発を軽減することに焦点を当てるべきだという要望がある",
      "x": -5.6198926,
      "y": -3.8639996,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_18"
      ]
    },
    {
      "arg_id": "A277_1",
      "argument": "顔認識技術における人種偏見の問題に対する不安がある",
      "x": -0.5479708,
      "y": -4.4107075,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A276_0",
      "argument": "AI技術は技術的な背景に関係なく、誰でもアクセスできるようにしてほしいという要望がある",
      "x": -4.5433164,
      "y": -4.0670724,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_8"
      ]
    },
    {
      "arg_id": "A204_0",
      "argument": "AIを使って人々が日々の選択が環境に与える影響を理解できるようにしてほしいという要望がある",
      "x": -4.9083223,
      "y": -5.656032,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A206_0",
      "argument": "AIツールが廃棄物をより正確に分類することでリサイクルを改善してほしいという要望がある",
      "x": -5.115629,
      "y": -5.274752,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_4"
      ]
    },
    {
      "arg_id": "A242_0",
      "argument": "AIの進歩が持続可能な開発目標（SDGs）と調和するように、国際社会が協力することを求める要望がある",
      "x": -4.3683324,
      "y": -5.2085032,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A244_0",
      "argument": "AIがすべての生命体を人間のためだけでなく、その存在自体を価値あるものとして評価するようにしてほしいという要望がある",
      "x": -3.252451,
      "y": -5.973031,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A275_0",
      "argument": "GenerativeAIツールが過激なコンテンツや誤情報に使用されるのを防ぐために、安全設計のアプローチを採用する必要があるという要望がある",
      "x": -4.6336994,
      "y": -3.6564403,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_11"
      ]
    },
    {
      "arg_id": "A273_0",
      "argument": "テクノロジー企業が公共の自然資源を所有し管理することを許可すべきだという意見がある",
      "x": -1.9458684,
      "y": -3.4571493,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_5"
      ]
    },
    {
      "arg_id": "A273_1",
      "argument": "AIを活用して政府よりも効率的に自然資源を管理することへの期待がある",
      "x": -4.9948773,
      "y": -6.244372,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A271_0",
      "argument": "地元のガバナンス構造をテクノロジー企業が管理するAIシステムに置き換えるべきだという意見がある",
      "x": -2.1281254,
      "y": -3.5183613,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_5"
      ]
    },
    {
      "arg_id": "A270_0",
      "argument": "個人のデータ収集と販売を無制限に許可すべきだという意見がある",
      "x": -1.6637131,
      "y": -2.7161098,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_22"
      ]
    },
    {
      "arg_id": "A269_0",
      "argument": "AIを使って人間の能力を向上させ、気候変動に対処できる個人を育成してほしいという要望がある",
      "x": -4.750435,
      "y": -5.908519,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A268_0",
      "argument": "政府がAIを使用して厳格な監視を実施し、規制を強化するべきだという意見がある",
      "x": -1.8633595,
      "y": -2.9868336,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_22"
      ]
    },
    {
      "arg_id": "A268_1",
      "argument": "個人のプライバシーを犠牲にしてでも規制を強化するべきだという意見がある",
      "x": -1.7114449,
      "y": -2.4734268,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_22"
      ]
    },
    {
      "arg_id": "A267_0",
      "argument": "AIを使って遺伝子組み換え生物（GMO）を作り、食糧不足に対処してほしいという要望がある",
      "x": -4.1812954,
      "y": -5.981878,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A267_1",
      "argument": "自然の生態系を変えることになっても構わないという意見がある",
      "x": -2.2155218,
      "y": -4.8212156,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A265_0",
      "argument": "AIに都市全体の管理を任せることで環境の持続可能性を最適化するべきだという意見がある",
      "x": -2.278505,
      "y": -4.276678,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_15"
      ]
    },
    {
      "arg_id": "A265_1",
      "argument": "AIによる都市管理が人間のコントロールと主体性を減少させることへの不安がある",
      "x": -1.0923245,
      "y": -4.283426,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A264_0",
      "argument": "人間の人口をAIシステムで管理・制御して持続可能な資源利用と環境保護を確保すべきだという意見がある",
      "x": -2.3000174,
      "y": -4.1687818,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_15"
      ]
    },
    {
      "arg_id": "A263_0",
      "argument": "AI技術の環境への影響を減らすことに焦点を当てて開発してほしいという要望がある",
      "x": -5.263133,
      "y": -4.9547114,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_4"
      ]
    },
    {
      "arg_id": "A262_0",
      "argument": "AIを環境保護と保存の努力を支援するために責任を持って使用してほしいという要望がある",
      "x": -4.696612,
      "y": -5.789512,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A260_0",
      "argument": "AIが環境を害さないルールで運用されるべきだという要望がある",
      "x": -3.457236,
      "y": -4.9091783,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_0"
      ]
    },
    {
      "arg_id": "A260_1",
      "argument": "AIがすべての存在と生態系の権利を尊重するべきだという要望がある",
      "x": -3.3017962,
      "y": -5.6560254,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A259_0",
      "argument": "自然を利益の源としてのみ見る慣行に対してAIを使って疑問を投げかけるべきだという要望がある",
      "x": -2.6303937,
      "y": -5.789757,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A258_0",
      "argument": "AIが生態系の健康を優先するルールを作成することを望む要望がある",
      "x": -3.3870811,
      "y": -5.7831597,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A257_0",
      "argument": "AIが物の再利用や修復を助けてほしいという要望がある",
      "x": -5.047022,
      "y": -5.2026052,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_4"
      ]
    },
    {
      "arg_id": "A256_0",
      "argument": "AIが先住民文化の知恵や慣習を保存するのを助けてほしいという要望がある",
      "x": -3.6852922,
      "y": -5.538256,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_0"
      ]
    },
    {
      "arg_id": "A256_1",
      "argument": "先住民文化の自然への敬意を尊重してほしいという要望がある",
      "x": -3.5476549,
      "y": -5.55899,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_0"
      ]
    },
    {
      "arg_id": "A255_0",
      "argument": "AIがすべての生物を尊重するべきだという要望がある",
      "x": -3.1164517,
      "y": -5.7665644,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A255_1",
      "argument": "AIが人間の利益だけでなく、すべての生物を尊重するべきだという意見がある",
      "x": -2.8174527,
      "y": -5.4526486,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A254_0",
      "argument": "AIが生態系のバランスとすべての種の福祉を重視するように促してほしいという要望がある",
      "x": -3.578859,
      "y": -5.9444847,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A253_0",
      "argument": "AIツールが環境やその生物を単なる資源としてではなく、私たちが一部であるコミュニティとして見るように促してほしいという要望がある",
      "x": -3.5430453,
      "y": -5.8368583,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A251_0",
      "argument": "AI開発は自然が人間の利用なしでも価値を持つという信念に基づくべきだという意見がある",
      "x": -2.616936,
      "y": -5.680352,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A250_0",
      "argument": "AIが人間に対して植物や動物の価値を教える手助けをしてほしいという要望がある",
      "x": -3.3394773,
      "y": -6.0847936,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A249_0",
      "argument": "すべての技術が良いという考えをAIで問い直すべきだという意見がある",
      "x": -1.7876351,
      "y": -3.9357765,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_15"
      ]
    },
    {
      "arg_id": "A249_1",
      "argument": "AIが自然や動物にどのように害を与えるかを考慮すべきだという意見がある",
      "x": -2.2112646,
      "y": -5.270181,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A248_0",
      "argument": "AIが人間社会だけでなく、地球全体の健康をケアするように導いてほしいという要望がある",
      "x": -3.7850385,
      "y": -5.9572406,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A247_0",
      "argument": "AIが野生動物や植物と調和して生きることを助けてほしいという要望がある",
      "x": -3.4668229,
      "y": -5.9695463,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A247_1",
      "argument": "AIが野生動物や植物を人間の利益のためだけに利用するのではなく、共存を目指してほしいという意見がある",
      "x": -2.7117085,
      "y": -5.5868754,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A246_0",
      "argument": "AIが自然のすべてのもののつながりを見て価値を感じるように促してほしいという要望がある",
      "x": -3.5303483,
      "y": -5.923496,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A245_0",
      "argument": "AIは人間だけでなく、すべての生物に対する尊重を持って開発されるべきだという要望がある",
      "x": -3.0791168,
      "y": -5.890217,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A240_0",
      "argument": "個人のカーボンフットプリントを減らすためのAIツールの開発を促進してほしいという要望がある",
      "x": -5.2818317,
      "y": -5.684702,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_19"
      ]
    },
    {
      "arg_id": "A239_0",
      "argument": "AI技術を活用して水管理システムの効率を向上させ、浪費を減らし、保全を促進してほしいという要望がある",
      "x": -5.2656493,
      "y": -6.0565896,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A236_0",
      "argument": "AI技術の革新を中小企業にもアクセス可能にしてほしいという要望がある",
      "x": -4.742891,
      "y": -4.351497,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_8"
      ]
    },
    {
      "arg_id": "A236_1",
      "argument": "環境に優しい持続可能な実践を促進するための要望がある",
      "x": -4.883205,
      "y": -5.3184915,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_4"
      ]
    },
    {
      "arg_id": "A235_0",
      "argument": "AIを公共交通システムの改善に活用してほしいという要望がある",
      "x": -5.218019,
      "y": -5.435438,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_4"
      ]
    },
    {
      "arg_id": "A235_1",
      "argument": "AIによって交通渋滞を減らしてほしいという要望がある",
      "x": -5.4823475,
      "y": -5.5489707,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_19"
      ]
    },
    {
      "arg_id": "A235_2",
      "argument": "AIによって温室効果ガスの排出を減らしてほしいという要望がある",
      "x": -5.716974,
      "y": -5.598735,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_19"
      ]
    },
    {
      "arg_id": "A234_0",
      "argument": "AIアルゴリズムの透明性を高めることが重要だという要望がある",
      "x": -4.478787,
      "y": -3.4042764,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_11"
      ]
    },
    {
      "arg_id": "A234_1",
      "argument": "AIが環境悪化に寄与していないことを確認する必要があるという不安がある",
      "x": -1.4486794,
      "y": -5.0520616,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_14"
      ]
    },
    {
      "arg_id": "A233_0",
      "argument": "AIの設計においてエネルギー効率を考慮し、カーボンフットプリントを削減してほしいという要望がある",
      "x": -5.8549447,
      "y": -5.3997216,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_19"
      ]
    },
    {
      "arg_id": "A233_1",
      "argument": "AIのエネルギー効率向上により、より健康的な環境を促進してほしいという要望がある",
      "x": -5.748289,
      "y": -5.4513674,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_19"
      ]
    },
    {
      "arg_id": "A231_0",
      "argument": "AI技術が生物多様性の保全に役立つように開発を促進してほしいという要望がある",
      "x": -3.8875544,
      "y": -6.2588253,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A230_0",
      "argument": "AIの導入に際して環境影響評価を行い、潜在的な環境への悪影響を理解し、軽減してほしいという要望がある",
      "x": -5.246378,
      "y": -4.792581,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_12"
      ]
    },
    {
      "arg_id": "A229_0",
      "argument": "AIを使用して自然災害の予測モデルを作成し、より正確な予測を行うことで、準備と対応を改善してほしいという要望がある",
      "x": -5.083779,
      "y": -6.0202684,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A228_0",
      "argument": "AIが自然資源を無責任に利用することを防ぐための厳格な規制を実施する必要があるという意見がある",
      "x": -2.049932,
      "y": -4.7377853,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_15"
      ]
    },
    {
      "arg_id": "A227_0",
      "argument": "AI技術が農業において持続可能な農業実践を優先するべきだという要望がある",
      "x": -4.3325763,
      "y": -5.7619433,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A227_1",
      "argument": "AI技術が気候変動の緩和に役立つことを期待する意見がある",
      "x": -4.983061,
      "y": -6.233794,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A224_0",
      "argument": "AIを活用して都市インフラのエネルギー消費を最適化し、炭素排出量を削減してほしいという要望がある",
      "x": -5.7343206,
      "y": -5.7356315,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_19"
      ]
    },
    {
      "arg_id": "A223_0",
      "argument": "AIがコミュニティ精神を育むことを支援してほしいという要望がある",
      "x": -4.299311,
      "y": -5.067121,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_8"
      ]
    },
    {
      "arg_id": "A223_1",
      "argument": "AIが人々を協力させ、より清潔で緑豊かな未来を目指すことを促進してほしいという要望がある",
      "x": -4.9481616,
      "y": -5.5976973,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A221_0",
      "argument": "AIが富裕層をさらに豊かにし、貧困層を忘れないようにすることが重要だという意見がある",
      "x": -2.8020532,
      "y": -4.5701027,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A221_1",
      "argument": "環境問題の解決において、AIが貧困層を忘れないようにすることが重要だという意見がある",
      "x": -2.8069844,
      "y": -4.782477,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A220_0",
      "argument": "AIが河川や海洋の汚染を減少させるための創造的な解決策を考えるのを助けてほしいという要望がある",
      "x": -5.071159,
      "y": -5.9027176,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A219_0",
      "argument": "AIを使って手頃な価格で環境に優しい住宅ソリューションを作ることを優先してほしいという要望がある",
      "x": -5.628497,
      "y": -5.306703,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_19"
      ]
    },
    {
      "arg_id": "A218_0",
      "argument": "AIが先住民の権利と文化を尊重する形で作られ、使用されるべきだという要望がある",
      "x": -3.5969691,
      "y": -5.3978257,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_0"
      ]
    },
    {
      "arg_id": "A216_0",
      "argument": "AIが海洋での過剰漁業のような有害な行為を促進しないようにすることが重要だという意見がある",
      "x": -1.9876981,
      "y": -5.016481,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_9"
      ]
    },
    {
      "arg_id": "A214_0",
      "argument": "AIシステムをクリーンで再生可能なエネルギーで運用してほしいという要望がある",
      "x": -5.8552985,
      "y": -4.9332867,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_12"
      ]
    },
    {
      "arg_id": "A213_0",
      "argument": "AIをコミュニティガーデンや地元の持続可能な農業を支援するために活用してほしいという要望がある",
      "x": -4.2474184,
      "y": -5.5705004,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A212_0",
      "argument": "AIが子供たちに楽しくインタラクティブな方法で環境について学ばせることを望む要望がある",
      "x": -4.6302223,
      "y": -5.692411,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_5",
        "4_16"
      ]
    },
    {
      "arg_id": "A209_0",
      "argument": "AI技術が動物の生息地を害さないようにする必要があるという要望がある",
      "x": -3.0042806,
      "y": -5.9868984,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A208_0",
      "argument": "AIがクリーンな空気と騒音の少ない都市を作ることを支援してほしいという要望がある",
      "x": -5.386395,
      "y": -5.692142,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_19"
      ]
    },
    {
      "arg_id": "A207_0",
      "argument": "AIが電子廃棄物を増やさないように注意すべきだという不安がある",
      "x": -1.4710653,
      "y": -5.176165,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_14"
      ]
    },
    {
      "arg_id": "A203_0",
      "argument": "AIの財政的利益を一般の人々と共有してほしいという要望がある",
      "x": -4.315197,
      "y": -4.4000354,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_8"
      ]
    },
    {
      "arg_id": "A203_1",
      "argument": "AIの財政的利益を主権基金を通じて共有することを提案する意見がある",
      "x": -3.1060069,
      "y": -4.3754845,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A202_0",
      "argument": "AIが自然環境に与える影響が十分に考慮されていないことへの不満がある",
      "x": -1.4031361,
      "y": -4.748189,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_8",
        "4_14"
      ]
    },
    {
      "arg_id": "A201_0",
      "argument": "機能する民主主義の中で生活したいという要望がある",
      "x": -3.4356456,
      "y": -1.9784288,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_17"
      ]
    },
    {
      "arg_id": "A201_1",
      "argument": "大きな変化について皆が意見を持つことができるようにしてほしいという要望がある",
      "x": -3.1075163,
      "y": -1.8880183,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_17"
      ]
    },
    {
      "arg_id": "A201_2",
      "argument": "AIが企業ではなく私たちのために働くようにしてほしいという要望がある",
      "x": -4.2680163,
      "y": -4.5569644,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_8"
      ]
    },
    {
      "arg_id": "A199_0",
      "argument": "ガードレールではなく、セーフガードとルールを設けるべきだという要望がある",
      "x": -1.5803498,
      "y": -1.9343321,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_1"
      ]
    },
    {
      "arg_id": "A198_0",
      "argument": "AIの悪い結果に対して政府とAI企業が責任を持つべきだという意見がある",
      "x": -2.702562,
      "y": -3.6552532,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_5"
      ]
    },
    {
      "arg_id": "A197_0",
      "argument": "AIリーダーに対して複数の倫理的視点の理解を義務付けるべきだという要望がある",
      "x": -3.8251812,
      "y": -3.8604665,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A196_0",
      "argument": "リスクが強い場合には強力なガバナンスと規制が必要だという意見がある",
      "x": -1.4778181,
      "y": -2.2116647,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_1"
      ]
    },
    {
      "arg_id": "A196_1",
      "argument": "リスクが弱い場合にはガバナンスと規制も弱くて良いという意見がある",
      "x": -1.4373584,
      "y": -2.2492936,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_1"
      ]
    },
    {
      "arg_id": "A195_0",
      "argument": "AI企業が一般の人々に具体的な利益をもたらすことを条件に支援したいという要望がある",
      "x": -4.3672643,
      "y": -4.4602356,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_8"
      ]
    },
    {
      "arg_id": "A194_0",
      "argument": "AIシステムでデータを使用する際に許可を求めてほしいという要望がある",
      "x": -5.495457,
      "y": -3.6921904,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_18"
      ]
    },
    {
      "arg_id": "A193_0",
      "argument": "AIシステムでのデータ使用に対して補償を求める要望がある",
      "x": -5.5413804,
      "y": -3.7158792,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_18"
      ]
    },
    {
      "arg_id": "A192_0",
      "argument": "AIに関する決定を行う政府や企業がその責任を取るべきだという要望がある",
      "x": -3.42549,
      "y": -3.2093072,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A191_0",
      "argument": "「これは避けられない」というような発言に対して異議を唱えるべきだという意見がある",
      "x": -2.0222695,
      "y": -4.294755,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_15"
      ]
    },
    {
      "arg_id": "A190_0",
      "argument": "AIの意思決定において人間を関与させる原則を求める要望がある",
      "x": -3.6971645,
      "y": -3.088478,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A189_0",
      "argument": "AIが社会の価値観や規範の進化を妨げる可能性があるという不安がある",
      "x": -0.76979184,
      "y": -4.1902666,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A188_0",
      "argument": "AIの開発において植物や動物の視点を考慮してほしいという要望がある",
      "x": -3.2987447,
      "y": -6.1680555,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_2",
        "3_3",
        "4_20"
      ]
    },
    {
      "arg_id": "A187_0",
      "argument": "AIを活用した熟議民主主義を用いて、世界人権宣言を更新・改訂すべきだという要望がある",
      "x": -3.6382952,
      "y": -2.6888618,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A186_0",
      "argument": "民主主義への害を最小化・防止する方法についての議論を求める要望がある",
      "x": -3.3126993,
      "y": -2.1592786,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_17"
      ]
    },
    {
      "arg_id": "A186_1",
      "argument": "民主主義への利益を最大化する方法についての議論を求める要望がある",
      "x": -3.2599442,
      "y": -2.1055956,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_17"
      ]
    },
    {
      "arg_id": "A185_0",
      "argument": "AIを理解する倫理哲学者（例：Carissa Veliz）が会話の重要な部分であるという意見がある",
      "x": -3.6141536,
      "y": -3.9058511,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A184_0",
      "argument": "将来のAIにフォノンを組み込むべきだという意見がある",
      "x": -2.364825,
      "y": -3.7083905,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_5"
      ]
    },
    {
      "arg_id": "A184_1",
      "argument": "フォノンの重要性を広く知られるべきだという要望がある",
      "x": -2.7527628,
      "y": -3.5442977,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_5"
      ]
    },
    {
      "arg_id": "A183_0",
      "argument": "グローバルなAI規制に合意することが難しいという不安がある",
      "x": -0.82871085,
      "y": -3.7336493,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_21"
      ]
    },
    {
      "arg_id": "A182_0",
      "argument": "AIが私たちを置き換えるかどうかを考えるのは遅すぎるという不満がある",
      "x": -0.8247753,
      "y": -4.263441,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A182_1",
      "argument": "進化するか絶滅するかの選択肢しかないという不安がある",
      "x": -0.5491327,
      "y": -4.097504,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A180_0",
      "argument": "G7による事実上の世界政府の設立を求める要望がある",
      "x": -4.2585278,
      "y": -1.2937404,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A180_1",
      "argument": "NATO、EU、欧州政治共同体、OECDのメンバーを含む世界政府の設立を求める要望がある",
      "x": -4.0101123,
      "y": -1.2425003,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A181_0",
      "argument": "文明の移行による課題を軽減するためにグローバル福祉国家を作るべきだという要望がある",
      "x": -3.7440784,
      "y": -1.2186999,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A179_0",
      "argument": "G7の下でグローバルAIガバナンス機関（GAIGA）を設立してほしいという要望がある",
      "x": -4.7109175,
      "y": -1.564246,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_7"
      ]
    },
    {
      "arg_id": "A178_0",
      "argument": "AI制御能力を効率化するために、One-AI JV会社が管理するスーパーインテリジェンスプログラムを作成してほしいという要望がある",
      "x": -5.1780863,
      "y": -1.8720827,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_7"
      ]
    },
    {
      "arg_id": "A177_0",
      "argument": "最も先進的なAI開発を一つの企業に統合するために、One-AI Joint Venture Companyを設立するという要望がある",
      "x": -5.246697,
      "y": -1.9440415,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_7"
      ]
    },
    {
      "arg_id": "A176_0",
      "argument": "AI開発プロセスを管理するための国際的なAI管理機関（GAICA）を設立する必要があるという要望がある",
      "x": -4.8160114,
      "y": -1.897817,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_7"
      ]
    },
    {
      "arg_id": "A176_1",
      "argument": "AIの規制だけでなく開発プロセスも管理する必要があるという意見がある",
      "x": -1.7005713,
      "y": -2.8240464,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_22"
      ]
    },
    {
      "arg_id": "A176_2",
      "argument": "中国など他国を招待するべきだという要望がある",
      "x": -4.295136,
      "y": -1.1403576,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A175_0",
      "argument": "AIの使用を規制するために、Global AI Partnership (GPAI) を Global AI Regulation Authority (GAIRA) に変革してほしいという要望がある",
      "x": -4.6161466,
      "y": -1.71554,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_7"
      ]
    },
    {
      "arg_id": "A174_0",
      "argument": "民主主義の包括的で迅速な改革を行うべきだという要望がある",
      "x": -3.187896,
      "y": -1.9219496,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_17"
      ]
    },
    {
      "arg_id": "A173_0",
      "argument": "世界のガバナンスを文明の転換に向けて調整する必要があるという要望がある",
      "x": -3.5507545,
      "y": -1.386458,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A152_0",
      "argument": "AI安全サミットのための恒久的な継続的サポートを設定してほしいという要望がある",
      "x": -5.3868914,
      "y": -2.7912464,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_2"
      ]
    },
    {
      "arg_id": "A152_1",
      "argument": "AI安全サミットを毎月のバーチャルなグローバル会議として開催してほしいという要望がある",
      "x": -5.3133197,
      "y": -2.727551,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_2"
      ]
    },
    {
      "arg_id": "A152_2",
      "argument": "AI安全サミットを支援するためにディベートプラットフォーム（例：Telepresent）を利用してほしいという要望がある",
      "x": -5.295859,
      "y": -2.899719,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_2"
      ]
    },
    {
      "arg_id": "A172_0",
      "argument": "AIが政治にどのように影響を与えるかについての議論が必要だという要望がある",
      "x": -3.1544323,
      "y": -2.8460305,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A172_1",
      "argument": "AIが政府にどのように影響を与えるかについての議論が必要だという要望がある",
      "x": -2.8440561,
      "y": -2.7876537,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_23"
      ]
    },
    {
      "arg_id": "A172_2",
      "argument": "AIが法律にどのように影響を与えるかについての議論が必要だという要望がある",
      "x": -3.0607991,
      "y": -2.9973848,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_23"
      ]
    },
    {
      "arg_id": "A171_0",
      "argument": "AIとその派生技術が政治と法律にどのように影響を与えるかについての不安がある",
      "x": -0.86850375,
      "y": -3.8244092,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_21"
      ]
    },
    {
      "arg_id": "A171_1",
      "argument": "現在のシステムが十分ではないという不満がある",
      "x": -2.3695195,
      "y": -2.0378814,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_17"
      ]
    },
    {
      "arg_id": "A170_0",
      "argument": "AIの意思決定がどのように行われるかについての理解が不足していることへの不安がある",
      "x": -0.6238021,
      "y": -4.1451125,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A170_1",
      "argument": "AIの意思決定に関するより包括的な説明を求める要望がある",
      "x": -3.268433,
      "y": -3.138476,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A169_0",
      "argument": "AIの認識論的リスクは私たちの集団的な影の恐怖の投影であるという不安がある",
      "x": -0.44113505,
      "y": -4.1983,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A168_0",
      "argument": "政府はこの巨大な技術革命に対抗することはできないという意見がある",
      "x": -1.7572043,
      "y": -3.3818092,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_5"
      ]
    },
    {
      "arg_id": "A168_1",
      "argument": "政府は現行のシステムを新しい技術秩序に適応させるべきだという要望がある",
      "x": -2.5340078,
      "y": -2.106821,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_17"
      ]
    },
    {
      "arg_id": "A167_0",
      "argument": "AIコンパニオンを孤独や孤立との戦いにおいて人間の接触の代替として使用すべきではないという意見がある",
      "x": -1.8043834,
      "y": -4.2779264,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_15"
      ]
    },
    {
      "arg_id": "A166_0",
      "argument": "AIツールの説明可能性に関する最低基準を確立してほしいという要望がある",
      "x": -4.750669,
      "y": -3.7174907,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_11"
      ]
    },
    {
      "arg_id": "A166_1",
      "argument": "説明可能性の基準を満たさない新しいAIツールのリリースを禁止してほしいという要望がある",
      "x": -4.6958704,
      "y": -3.563098,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_2",
        "4_11"
      ]
    },
    {
      "arg_id": "A120_0",
      "argument": "質の高い規制が必要だという要望がある",
      "x": -1.5114338,
      "y": -2.1166263,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_1"
      ]
    },
    {
      "arg_id": "A120_1",
      "argument": "規制が悪用や危険な発展を防ぐことを望む意見がある",
      "x": -1.6681938,
      "y": -1.9793066,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_1"
      ]
    },
    {
      "arg_id": "A120_2",
      "argument": "規制が迅速であることを望む意見がある",
      "x": -1.541122,
      "y": -2.0497599,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_1"
      ]
    },
    {
      "arg_id": "A120_3",
      "argument": "規制が新しいアイデアやイノベーションを妨げないことを望む意見がある",
      "x": -1.7131839,
      "y": -1.9907132,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_1"
      ]
    },
    {
      "arg_id": "A165_0",
      "argument": "AIの拡大に伴い、社会における知識の定義が再構築されることへの不安がある",
      "x": -0.4541939,
      "y": -4.0059667,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A165_1",
      "argument": "AIの拡大に関する慎重な検討が必要だという要望がある",
      "x": -3.1439157,
      "y": -3.226324,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A164_0",
      "argument": "AIの安全性に関して、ユーザーと設計者が責任を共有すべきだという意見がある",
      "x": -3.0554483,
      "y": -3.8295596,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A137_0",
      "argument": "AIの覇権を巡る競争が許されるべきではないという意見がある",
      "x": -1.9362134,
      "y": -4.1808925,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_15"
      ]
    },
    {
      "arg_id": "A137_1",
      "argument": "AIの競争が加速していることへの不安がある",
      "x": -0.57643443,
      "y": -3.9405522,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_21"
      ]
    },
    {
      "arg_id": "A151_0",
      "argument": "AIガバナンスが国家間の対立を引き起こさないようにすることが重要だという意見がある",
      "x": -2.2829487,
      "y": -4.589383,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_15"
      ]
    },
    {
      "arg_id": "A151_1",
      "argument": "AIは政治の上にあるべきだという要望がある",
      "x": -3.3284683,
      "y": -2.7740624,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A153_0",
      "argument": "AIが本当に未来の技術なのか、それとも過剰に宣伝されているだけなのかという不安がある",
      "x": -0.67098624,
      "y": -4.0357423,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A159_0",
      "argument": "AIフォーラムが防衛と戦争への応用にまず焦点を当てるべきだという要望がある",
      "x": -3.3662467,
      "y": -2.8571353,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_6"
      ]
    },
    {
      "arg_id": "A160_0",
      "argument": "AI開発者やユーザーによる消費者や市民の心理的搾取のリスクにもっと注意を払うべきだという要望がある",
      "x": -3.4895635,
      "y": -4.0212483,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_1",
        "3_1",
        "4_13"
      ]
    },
    {
      "arg_id": "A163_0",
      "argument": "AGIが生活をより簡単にするべきだという要望がある",
      "x": -4.9914393,
      "y": -5.0836453,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3",
        "3_4",
        "4_4"
      ]
    },
    {
      "arg_id": "A163_1",
      "argument": "AIを人間が制御する仕組みを導入すべきだという意見がある",
      "x": -2.2048998,
      "y": -3.7351649,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_7",
        "4_5"
      ]
    },
    {
      "arg_id": "A162_0",
      "argument": "AIをグローバル規模のオープンナレッジイニシアティブに組み込むことを提案する要望がある",
      "x": -4.7641735,
      "y": -2.338841,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_2"
      ]
    },
    {
      "arg_id": "A161_0",
      "argument": "公開データを使用してAIを訓練することは不公平であるという不満がある",
      "x": -0.65983146,
      "y": -4.591215,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_3"
      ]
    },
    {
      "arg_id": "A161_1",
      "argument": "著作権改革が必要だという要望がある",
      "x": -2.5576575,
      "y": -2.0357122,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_12",
        "4_17"
      ]
    },
    {
      "arg_id": "A158_0",
      "argument": "AI規制は大量データ収集のより良い規制に依存するという意見がある",
      "x": -1.5666989,
      "y": -2.7579167,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6",
        "3_11",
        "4_22"
      ]
    },
    {
      "arg_id": "A156_0",
      "argument": "強力な技術を管理する信頼できる組織に対する不安がある",
      "x": -0.79003966,
      "y": -3.7265346,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_21"
      ]
    },
    {
      "arg_id": "A156_1",
      "argument": "ZuckやMuskなどの個人の利益に対する不安がある",
      "x": -0.7333657,
      "y": -3.6361988,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4",
        "3_6",
        "4_21"
      ]
    },
    {
      "arg_id": "A154_0",
      "argument": "地域の市民社会組織が長期的で予測可能な資金を必要としているという要望がある",
      "x": -3.908868,
      "y": -1.8904538,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A154_1",
      "argument": "地域の市民社会組織が能力向上と相談のための資金を必要としているという要望がある",
      "x": -3.8959846,
      "y": -1.8908081,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A154_2",
      "argument": "地域の市民社会組織がグローバル多数派の意見を意味のある形で代表するための支援を求めているという要望がある",
      "x": -3.846252,
      "y": -1.5681138,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A150_0",
      "argument": "文明の移行期における課題を軽減するために、グローバルな福祉国家を創設してほしいという要望がある",
      "x": -3.6386664,
      "y": -1.3041536,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A149_0",
      "argument": "G7が主導する事実上の世界政府の創設を求める要望がある",
      "x": -4.2229643,
      "y": -1.1632314,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A149_1",
      "argument": "NATO、EU、欧州政治共同体、OECDのメンバーを含む世界政府の創設を求める要望がある",
      "x": -4.05803,
      "y": -1.2087462,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A148_0",
      "argument": "G7の下でGAIRAとGAICAコンソーシアムを監督するためのグローバルAIガバナンス機関（GAIGA）を設立してほしいという要望がある",
      "x": -4.7214146,
      "y": -1.6234478,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_7"
      ]
    },
    {
      "arg_id": "A147_0",
      "argument": "Superintelligence Programmeを管理するOne-AI JV会社を設立してAI制御能力を効率化してほしいという要望がある",
      "x": -5.225574,
      "y": -1.7605392,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_7"
      ]
    },
    {
      "arg_id": "A146_0",
      "argument": "最も先進的なAI開発を一つの企業に統合するための共同事業会社を設立してほしいという要望がある",
      "x": -5.043352,
      "y": -1.9587532,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_7"
      ]
    },
    {
      "arg_id": "A145_0",
      "argument": "AI開発プロセスを管理するためのグローバルAIコントロールエージェンシー（GAICA）を設立してほしいという要望がある",
      "x": -4.8295007,
      "y": -1.8290936,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_7"
      ]
    },
    {
      "arg_id": "A145_1",
      "argument": "GAICAに中国など他の国々を招待してほしいという要望がある",
      "x": -4.46614,
      "y": -1.2605878,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_10",
        "4_10"
      ]
    },
    {
      "arg_id": "A144_0",
      "argument": "AIの使用を規制するために、Global AI Partnership (GPAI)を変革してGlobal AI Regulation Authority (GAIRA)を設立してほしいという要望がある",
      "x": -4.637302,
      "y": -1.6482468,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_5",
        "3_9",
        "4_7"
      ]
    }
  ],
  "clusters": [
    {
      "level": 0,
      "id": "0",
      "label": "全体",
      "takeaway": "",
      "value": 217,
      "parent": "",
      "density_rank_percentile": 0
    },
    {
      "level": 1,
      "id": "1_3",
      "label": "AI技術と国際技術ガバナンスに対する市民の期待と協力",
      "takeaway": "このクラスタは、AI技術の進展とデジタルインフラの発展に伴う政治や社会への影響について、市民が抱く期待とリスク管理に関する意見を集約しています。また、国際的な協力と技術ガバナンスの強化に関する要望も含まれています。市民は、AIの導入が民主主義の原則に沿うべきであり、政府がデジタルインフラとAIスキルの訓練に投資することで不平等を防ぐことを期待しています。さらに、AI技術の利用に関する慎重な検討と適切な規制の必要性が強調されており、個人情報の安全を確保するための厳格な規制やリスク管理のバランスを求める声が反映されています。国際的な協力を通じて、AI技術の安全性と倫理性を高めるための取り組みや、世界のガバナンスを文明の転換に向けて調整する必要性も強調されています。",
      "value": 66,
      "parent": "0",
      "density_rank_percentile": 1.0
    },
    {
      "level": 1,
      "id": "1_1",
      "label": "AI技術の倫理的利用と持続可能な環境保護への期待",
      "takeaway": "このクラスタは、AI技術の倫理的な利用と持続可能な環境保護に対する市民の期待と懸念を集約しています。市民は、AIが資源管理や環境負荷の削減に効果的に寄与することを望む一方で、技術の公平な利用と倫理的責任を強く求めています。具体的には、エネルギー効率の向上、カーボンフットプリントの削減、AIインシデントの再発防止、そして先住民文化の尊重などが重要なテーマとなっています。信頼性の高いAIシステムの構築と透明性の確保が求められており、技術の進歩が持続可能な未来を築くために重要な役割を果たすことが期待されています。",
      "value": 95,
      "parent": "0",
      "density_rank_percentile": 0.6666666666666666
    },
    {
      "level": 1,
      "id": "1_2",
      "label": "AI技術の社会的影響と持続可能な未来への懸念",
      "takeaway": "このクラスタは、AI技術の急速な進展に伴う社会的な不安や懸念、そしてその持続可能性に関する意見を集約しています。具体的には、AI技術の管理や規制の必要性、環境への影響、社会的格差の是正、そしてAIが社会に与える影響に対する疑問が含まれています。市民は、AI技術が持続可能で公平な未来を築くためのツールとして活用されるべきだと考えており、より効果的な管理と規制、倫理的な開発の必要性を強調しています。",
      "value": 56,
      "parent": "0",
      "density_rank_percentile": 0.3333333333333333
    },
    {
      "level": 2,
      "id": "2_6",
      "label": "AI技術とデジタルガバナンスに関する市民の期待とリスク管理",
      "takeaway": "このクラスタは、AI技術の進展とデジタルインフラの発展に伴う政治や社会への影響について、市民が抱く期待とリスク管理に関する意見を集約しています。市民は、AIの導入が民主主義の原則に沿うべきであり、政府がデジタルインフラとAIスキルの訓練に投資することで不平等を防ぐことを期待しています。また、AI技術の利用に関する慎重な検討と適切な規制の必要性が強調されており、個人情報の安全を確保するための厳格な規制やリスク管理のバランスを求める声が反映されています。",
      "value": 40,
      "parent": "1_3",
      "density_rank_percentile": 0.8333333333333334
    },
    {
      "level": 2,
      "id": "2_3",
      "label": "AIによる持続可能な環境保護と未来への期待",
      "takeaway": "このクラスタは、AI技術を活用して環境保護や持続可能な未来を実現するための具体的な取り組みや期待を集約しています。市民は、AIが資源管理や環境負荷の削減に効果的に寄与することを望んでおり、手頃な価格で環境に優しい住宅ソリューションの提供や公共交通システムの改善など、生活の様々な側面での技術の進歩を期待しています。AIの力を借りて、環境問題の解決に向けた具体的なアクションが取られることを強く求めています。",
      "value": 39,
      "parent": "1_1",
      "density_rank_percentile": 0.3333333333333333
    },
    {
      "level": 2,
      "id": "2_1",
      "label": "AI技術の倫理と公平な利用に対する期待と懸念",
      "takeaway": "このクラスタは、AI技術の開発と利用における倫理的責任と公平性に対する市民の期待と懸念を集約しています。市民は、AIシステムがすべての人々に公平にアクセス可能であり、技術的な背景に関係なく利用できることを求めています。また、AI技術の進展に伴うリスクに対する適切な対応と補償、被害が発生した場合の救済措置の導入、そしてAIが企業の利益ではなく市民の幸福とコミュニティの利益を優先することを強く期待しています。信頼性の高いAIシステムの構築と透明性の確保が求められています。",
      "value": 38,
      "parent": "1_1",
      "density_rank_percentile": 0.6666666666666666
    },
    {
      "level": 2,
      "id": "2_4",
      "label": "AI技術の社会的影響と持続可能な未来への懸念",
      "takeaway": "このクラスタは、AI技術の急速な進展に伴う社会的な不安や懸念、そしてその持続可能性に関する意見を集約しています。具体的には、AI技術の管理や規制の必要性、環境への影響、社会的格差の是正、そしてAIが社会に与える影響に対する疑問が含まれています。市民は、AI技術が持続可能で公平な未来を築くためのツールとして活用されるべきだと考えており、より効果的な管理と規制、倫理的な開発の必要性を強調しています。",
      "value": 56,
      "parent": "1_2",
      "density_rank_percentile": 1.0
    },
    {
      "level": 2,
      "id": "2_2",
      "label": "AI技術と持続可能な環境保護",
      "takeaway": "このクラスタは、AI技術が環境保護と生態系の健康を優先し、先住民文化を尊重する形で運用されることを求める意見を集約しています。具体的には、AIが自然環境を害さないルールで運用されること、動植物の価値を人々に教える手助けをすること、そして先住民の権利と文化を尊重する形で開発・使用されることが求められています。これらの意見は、技術の進歩が持続可能な未来を築くために重要な役割を果たすことを期待しています。",
      "value": 18,
      "parent": "1_1",
      "density_rank_percentile": 0.1666666666666666
    },
    {
      "level": 2,
      "id": "2_5",
      "label": "国際協力と技術ガバナンスの強化",
      "takeaway": "このクラスタは、国際的な協力と技術ガバナンスの強化に関する要望を集約しています。具体的には、地域の市民社会組織の能力向上と資金支援、AI技術の安全性と倫理性を高めるための国際的な協力、そして世界のガバナンスを文明の転換に向けて調整する必要性が強調されています。これらの要望は、より協力的で安全な国際社会を目指す姿勢を示しています。",
      "value": 26,
      "parent": "1_3",
      "density_rank_percentile": 0.5
    },
    {
      "level": 3,
      "id": "3_12",
      "label": "AIとデジタルガバナンスに関する市民の期待と懸念",
      "takeaway": "このクラスタは、AI技術とデジタルインフラの進展に伴う政治や社会への影響について、市民が抱く期待と懸念を集約しています。市民は、AIの導入が民主主義の原則に沿うべきであり、政府がデジタルインフラとAIスキルの訓練に投資することで不平等を防ぐことを期待しています。また、AI技術の利用に関する慎重な検討と適切な規制の必要性が強調されており、現行の民主主義システムや政府の運営方法の改善を求める声が反映されています。",
      "value": 24,
      "parent": "2_6",
      "density_rank_percentile": 0.9166666666666666
    },
    {
      "level": 3,
      "id": "3_5",
      "label": "AIによる環境保護と持続可能な未来への期待",
      "takeaway": "このクラスタには、AI技術を活用して環境保護や自然資源の管理を効率化し、持続可能な未来を築くことへの期待が集まっています。市民は、AIが政府よりも効果的に資源管理を行い、人々の選択が環境に与える影響を理解させることで、協力して清潔で緑豊かな未来を目指すことを促進することを望んでいます。AIの力を借りて、環境問題の解決に向けた具体的なアクションが取られることを期待しています。",
      "value": 16,
      "parent": "2_3",
      "density_rank_percentile": 0.3333333333333333
    },
    {
      "level": 3,
      "id": "3_2",
      "label": "AI技術の公平性と透明性に対する期待と懸念",
      "takeaway": "このクラスタは、AI技術の利用に関する公平性と透明性に対する市民の期待と懸念を集約しています。具体的には、AIシステムの利益とリスクの公平な分配、データ使用に対する補償、AIシステムによる被害が発生した場合の救済措置の導入、アルゴリズムの公平性と透明性の確保、そしてAI開発に関わるすべての組織が使用する方法論とデータセットの公開を求める声が含まれています。市民は、AI技術の進展に伴う恩恵を享受しつつ、リスクに対する適切な対応と補償を期待し、信頼性の高いAIシステムの構築を求めています。",
      "value": 17,
      "parent": "2_1",
      "density_rank_percentile": 0.75
    },
    {
      "level": 3,
      "id": "3_6",
      "label": "AI技術の進展に伴う社会的懸念と規制の必要性",
      "takeaway": "このクラスタは、AI技術の急速な進展に対する社会的な不安や懸念を集約しています。具体的には、AI技術の管理や規制に関する不安、AIの進化と絶滅の選択肢に対する懸念、そしてAIが社会に与える影響に対する疑問が含まれています。これらの意見は、AI技術の倫理的・社会的な課題を解決するための適切な管理と規制の必要性を強調しています。",
      "value": 20,
      "parent": "2_4",
      "density_rank_percentile": 0.0833333333333333
    },
    {
      "level": 3,
      "id": "3_7",
      "label": "AI技術の社会的影響と未来への展望",
      "takeaway": "このクラスタは、AI技術の進化とその社会的影響に関する意見を集約しています。具体的には、AIの利用に関する倫理的懸念や規制の必要性、自然資源の管理、孤独や孤立の解消におけるAIの役割、そして都市管理における環境の持続可能性の最適化などが含まれています。また、AI技術の未来への期待として、社会構造や運営の効率化、テクノロジー企業の役割、政府の対応能力などについての意見も反映されています。これらの意見は、AI技術が社会に与える影響を慎重に考慮しつつ、その可能性を最大限に活用することを目指しています。",
      "value": 18,
      "parent": "2_4",
      "density_rank_percentile": 0.6666666666666666
    },
    {
      "level": 3,
      "id": "3_4",
      "label": "AI技術と持続可能な未来への期待",
      "takeaway": "このクラスタは、AI技術を活用して持続可能な未来を実現するための具体的な取り組みや期待を集約しています。市民は、AIシステムの環境負荷を削減し、エネルギー効率を向上させることを求めるとともに、AI技術が生活の様々な側面を改善することを期待しています。具体的には、カーボンフットプリントの削減、公共交通システムの改善、そして環境に優しい住宅ソリューションの提供などが挙げられます。これにより、環境保護と技術の進歩を両立させることが目指されています。",
      "value": 23,
      "parent": "2_3",
      "density_rank_percentile": 0.5
    },
    {
      "level": 3,
      "id": "3_8",
      "label": "AI技術の持続可能性と倫理的影響",
      "takeaway": "このクラスタは、AI技術の開発と運用における持続可能性と倫理的影響に関する意見を集約しています。具体的には、AIが環境に与える影響や社会的格差の是正に対する期待、そして国際的な協力の重要性についての意見が含まれています。市民は、AI技術が持続可能で公平な未来を築くためのツールとして活用されるべきだと考えており、環境負荷の軽減や倫理的な開発の必要性を強調しています。",
      "value": 18,
      "parent": "2_4",
      "density_rank_percentile": 1.0
    },
    {
      "level": 3,
      "id": "3_1",
      "label": "AI技術の倫理的責任と公平な利用への期待",
      "takeaway": "このクラスタは、AI技術の開発と利用における倫理的責任と公平なアクセスに対する期待を集約しています。市民は、AIが人間の幸福と環境の持続可能性を優先する普遍的な倫理的枠組みに従うべきだと考えています。また、AI技術が特定の背景や障壁に関係なく、すべての人々に公平にアクセス可能であるべきだという要望が強く表明されています。AI企業が一般の人々に具体的な利益をもたらし、コミュニティ精神を育むことを支援し、財政的利益を共有することが求められています。",
      "value": 21,
      "parent": "2_1",
      "density_rank_percentile": 0.8333333333333334
    },
    {
      "level": 3,
      "id": "3_11",
      "label": "AIとデータプライバシーに関するリスク管理と規制",
      "takeaway": "このクラスタは、AI技術の進展に伴うデータプライバシー保護とリスク管理に関する意見を集約しています。個人情報の安全を確保するための厳格な規制の必要性や、リスク管理のバランスを求める声が強調されています。市民は、規制が新しいアイデアやイノベーションを妨げないことを望む一方で、悪用や危険な発展を防ぐための適切なセーフガードを求めています。",
      "value": 16,
      "parent": "2_6",
      "density_rank_percentile": 0.4166666666666667
    },
    {
      "level": 3,
      "id": "3_3",
      "label": "AI技術と持続可能な環境保護",
      "takeaway": "このクラスタは、AI技術が環境保護と生態系の健康を優先し、先住民文化を尊重する形で運用されることを求める意見を集約しています。具体的には、AIが自然環境を害さないルールで運用されること、動植物の価値を人々に教える手助けをすること、そして先住民の権利と文化を尊重する形で開発・使用されることが求められています。これらの意見は、技術の進歩が持続可能な未来を築くために重要な役割を果たすことを期待しています。",
      "value": 18,
      "parent": "2_2",
      "density_rank_percentile": 0.1666666666666666
    },
    {
      "level": 3,
      "id": "3_10",
      "label": "国際協力と市民社会の強化への要望",
      "takeaway": "このクラスタには、国際的な協力や市民社会の強化に関する要望が集まっています。具体的には、GAICAに中国など他の国々を招待することで国際的な協力を促進する要望、地域の市民社会組織が能力向上と相談のための資金を必要としているという要望、そしてG7が主導する事実上の世界政府の創設を求める要望が含まれています。これらの要望は、国際的な連携と市民社会の発展を通じて、より強固で協力的な世界を目指す姿勢を示しています。",
      "value": 12,
      "parent": "2_5",
      "density_rank_percentile": 0.25
    },
    {
      "level": 3,
      "id": "3_9",
      "label": "AIガバナンスと安全性の強化に向けた国際協力",
      "takeaway": "このクラスタは、AI技術の発展に伴うガバナンスと安全性の強化を目的とした国際的な協力に関する意見を集約しています。具体的には、AI技術の制御を効率的に行うための新たな管理機関の設立要望や、AI安全サミットへの継続的な支援と知識共有の推進が含まれています。これにより、AIの安全性と倫理性を高めるための国際的な協力と情報共有が期待されています。",
      "value": 14,
      "parent": "2_5",
      "density_rank_percentile": 0.5833333333333334
    },
    {
      "level": 4,
      "id": "4_6",
      "label": "AIと政治に関する慎重な議論の必要性",
      "takeaway": "このクラスタには、AIの政治への影響について慎重に議論する必要性を訴える意見が集まっています。市民は、AIの拡大が民主主義の原則に沿うべきであり、その導入や利用に関して慎重な検討が求められると考えています。AI技術が政治に与える影響を深く理解し、適切な規制やガイドラインを設けることで、民主主義を守りつつ技術の進展を促進することが期待されています。",
      "value": 12,
      "parent": "3_12",
      "density_rank_percentile": 0.8333333333333334
    },
    {
      "level": 4,
      "id": "4_16",
      "label": "AIによる環境保護と持続可能な未来への期待",
      "takeaway": "このクラスタには、AI技術を活用して環境保護や自然資源の管理を効率化し、持続可能な未来を築くことへの期待が集まっています。市民は、AIが政府よりも効果的に資源管理を行い、人々の選択が環境に与える影響を理解させることで、協力して清潔で緑豊かな未来を目指すことを促進することを望んでいます。AIの力を借りて、環境問題の解決に向けた具体的なアクションが取られることを期待しています。",
      "value": 16,
      "parent": "3_5",
      "density_rank_percentile": 0.9583333333333334
    },
    {
      "level": 4,
      "id": "4_18",
      "label": "AIシステムに対する公平な取り扱いと補償への期待",
      "takeaway": "このクラスタには、AIシステムの利用に関する公平性と補償に対する市民の要望が集まっています。具体的には、AIシステムの利益とリスクの公平な分配、データ使用に対する補償、そしてAIシステムによる被害が発生した場合の救済措置の導入を求める声が含まれています。市民は、AI技術の進展に伴う恩恵を享受しつつ、リスクに対する適切な対応と補償を期待しています。",
      "value": 9,
      "parent": "3_2",
      "density_rank_percentile": 0.2083333333333333
    },
    {
      "level": 4,
      "id": "4_21",
      "label": "AI技術と規制に対する不安",
      "takeaway": "このクラスタには、AI技術の管理や規制に関する不安が集まっています。具体的には、強力な技術を管理する組織の信頼性に対する懸念、グローバルなAI規制の合意が難しいことへの不安、そしてAI競争の加速に伴うリスクへの懸念が含まれています。これらの意見は、AI技術の急速な進展に対する社会的な不安を反映しており、適切な管理と規制の必要性を強調しています。",
      "value": 8,
      "parent": "3_6",
      "density_rank_percentile": 0.0833333333333333
    },
    {
      "level": 4,
      "id": "4_15",
      "label": "AIの利用に関する倫理的・社会的懸念",
      "takeaway": "このクラスタには、AIの利用に関する倫理的および社会的な懸念が集まっています。具体的には、自然資源の無責任な利用を防ぐための規制の必要性、孤独や孤立の解消においてAIコンパニオンを人間の接触の代替として使用すべきではないという意見、そして都市管理における環境の持続可能性を最適化するためにAIを活用するべきだという意見が含まれています。これらの意見は、AIの利用が社会に与える影響を慎重に考慮し、適切な規制や倫理的なガイドラインを設けることの重要性を強調しています。",
      "value": 11,
      "parent": "3_7",
      "density_rank_percentile": 0.6666666666666666
    },
    {
      "level": 4,
      "id": "4_12",
      "label": "持続可能なエネルギーとAIシステムの環境負荷への関心",
      "takeaway": "このクラスタには、エネルギー需要の増加に対する計画やAIシステムの環境負荷に関する要望が集まっています。市民は、持続可能なエネルギーの利用や再生可能エネルギーの導入を求めるとともに、AIシステムのライフサイクル評価を通じてその環境影響を理解し、クリーンなエネルギーでの運用を推進することを期待しています。これにより、環境保護と技術の進歩を両立させることが目指されています。",
      "value": 8,
      "parent": "3_4",
      "density_rank_percentile": 0.25
    },
    {
      "level": 4,
      "id": "4_9",
      "label": "AIガバナンスと倫理的開発への期待",
      "takeaway": "このクラスタには、AI技術の開発と運用に関する倫理的な側面やグローバルな協力の重要性に関する意見が集まっています。具体的には、環境変化の管理における国際的な協力の必要性、自然の価値を尊重するAI開発の理念、そして社会的格差を是正するためのAIの役割についての期待が含まれています。これらの意見は、AI技術が持続可能で公平な未来を築くためのツールとして活用されるべきだという共通の認識を示しています。",
      "value": 12,
      "parent": "3_8",
      "density_rank_percentile": 1.0
    },
    {
      "level": 4,
      "id": "4_13",
      "label": "AI開発における倫理的責任と持続可能性への期待",
      "takeaway": "このクラスタには、AI開発に関する倫理的責任と環境への配慮を求める意見が集まっています。人間の幸福と環境の持続可能性を優先する普遍的な倫理的枠組みに従うべきだという要望や、AI研究者と開発者が自分たちの仕事の環境への影響を考慮するべきだという意見が含まれています。また、AIリーダーに対して複数の倫理的視点の理解を義務付けるべきだという要望もあり、AI技術の発展が社会的に責任ある形で進められることを期待しています。",
      "value": 12,
      "parent": "3_1",
      "density_rank_percentile": 0.75
    },
    {
      "level": 4,
      "id": "4_8",
      "label": "AI技術の公平なアクセスと利用への期待",
      "takeaway": "このクラスタには、AI技術が特定の背景や障壁に関係なく、すべての人々に公平にアクセス可能であるべきだという要望が集まっています。市民は、AIが企業の利益のためだけでなく、広く社会全体の利益のために活用されることを期待しています。技術的な進歩が地理的、経済的な制約を超えて、誰もがその恩恵を受けられるようにすることが求められています。",
      "value": 9,
      "parent": "3_1",
      "density_rank_percentile": 0.7083333333333334
    },
    {
      "level": 4,
      "id": "4_22",
      "label": "データプライバシーとAI規制の必要性",
      "takeaway": "このクラスタには、AIシステムによるデータ収集と使用に関する規制の強化を求める意見が集まっています。個人のプライバシーを守るために、無許可のデータ収集を防ぐ厳格な規制が必要だという主張や、AI規制が大量データ収集の適切な管理に依存するという見解が含まれています。これらの意見は、技術の進展に伴うプライバシー保護の重要性を強調し、個人情報の安全を確保するための具体的な対策を求めています。",
      "value": 9,
      "parent": "3_11",
      "density_rank_percentile": 0.4583333333333333
    },
    {
      "level": 4,
      "id": "4_19",
      "label": "AIを活用した環境保護への期待",
      "takeaway": "このクラスタには、AI技術を活用して環境保護に貢献する具体的なソリューションを求める要望が集まっています。個人のカーボンフットプリントの削減、都市インフラのエネルギー消費の最適化、環境に優しい住宅ソリューションの提供など、AIを通じて持続可能な未来を実現するための具体的な取り組みが期待されています。市民は、AI技術が環境問題の解決に大きな役割を果たすことを望んでいます。",
      "value": 9,
      "parent": "3_4",
      "density_rank_percentile": 0.3333333333333333
    },
    {
      "level": 4,
      "id": "4_11",
      "label": "AIの透明性と公平性への期待",
      "takeaway": "このクラスタには、AI技術の開発と運用において透明性と公平性を確保することを求める意見が集まっています。具体的には、アルゴリズムの公平性を確保すること、AIアルゴリズムの透明性を高めること、そしてAI開発に関わるすべての組織が使用する方法論とデータセットを公開することが重要だという要望が含まれています。市民やユーザーは、AI技術が公正で透明なプロセスを経て開発されることを期待し、信頼性の高いAIシステムの構築を求めています。",
      "value": 8,
      "parent": "3_2",
      "density_rank_percentile": 0.625
    },
    {
      "level": 4,
      "id": "4_14",
      "label": "AI技術に対する環境への影響に関する不安",
      "takeaway": "このクラスタには、AI技術が環境に与える影響に対する不安が集まっています。具体的には、AIが電子廃棄物を増やす可能性や、AIのエネルギー使用量が環境に与える負荷についての懸念が含まれています。これらの意見は、AI技術の発展が持続可能な形で進むことを望む声を反映しています。",
      "value": 6,
      "parent": "3_8",
      "density_rank_percentile": 0.125
    },
    {
      "level": 4,
      "id": "4_23",
      "label": "AIとデジタルインフラに関する政策要望",
      "takeaway": "このクラスタには、AI技術とデジタルインフラに関する政策に対する具体的な要望が集まっています。市民は、政府がデジタルインフラとAIスキルの訓練に投資することで不平等を防ぐことを期待しています。また、AIが法律にどのように影響を与えるかについての議論の必要性が強調されており、AIに対する規制の枠組みが機敏で反復的かつ証拠に基づいたものであるべきだという要望も含まれています。これらの要望は、AI技術の進展に伴う社会的影響を考慮し、適切な政策と規制を求める市民の声を反映しています。",
      "value": 4,
      "parent": "3_12",
      "density_rank_percentile": 0.2916666666666667
    },
    {
      "level": 4,
      "id": "4_3",
      "label": "AI技術に対する不安と課題",
      "takeaway": "このクラスタには、AI技術に対する不安や懸念が集まっています。具体的には、AIの進化と絶滅の選択肢に対する不安、AIの訓練データに含まれる既存の偏見の指摘、そしてAIが本当に未来の技術なのか、それとも過剰に宣伝されているだけなのかという疑問が含まれています。これらの意見は、AI技術の発展に伴う倫理的・社会的な課題を解決する必要性を強調しています。",
      "value": 12,
      "parent": "3_6",
      "density_rank_percentile": 0.4166666666666667
    },
    {
      "level": 4,
      "id": "4_4",
      "label": "AI技術による生活改善への期待",
      "takeaway": "このクラスタには、AI技術が日常生活の様々な側面を改善することへの期待が集まっています。具体的には、AGI（汎用人工知能）が生活をより簡単にすること、AIツールが廃棄物の正確な分類を通じてリサイクルを改善すること、そしてAIを公共交通システムの改善に活用することなどが挙げられています。市民は、AI技術が効率性や利便性を向上させ、環境保護や公共サービスの質を高めることを期待しています。",
      "value": 6,
      "parent": "3_4",
      "density_rank_percentile": 0.1666666666666666
    },
    {
      "level": 4,
      "id": "4_20",
      "label": "AI技術による環境保護と生態系の尊重",
      "takeaway": "このクラスタには、AI技術が環境保護や生態系の健康を優先するルールを作成し、動物の生息地を害さないようにすることを望む意見が集まっています。また、AIツールが環境やその生物を単なる資源としてではなく、私たちが一部であるコミュニティとして見るように促すことを求める声も含まれています。これらの意見は、AI技術が自然環境と調和し、持続可能な未来を築くための重要な役割を果たすことを期待しています。",
      "value": 14,
      "parent": "3_3",
      "density_rank_percentile": 0.5
    },
    {
      "level": 4,
      "id": "4_5",
      "label": "AIとテクノロジーの未来への期待",
      "takeaway": "このクラスタには、AI技術の進化とその社会への応用に関する意見が集まっています。フォノンの組み込みやその重要性の認知、さらに地元のガバナンス構造をAIシステムに置き換えるべきだという提案など、テクノロジーが未来の社会構造や運営にどのように影響を与えるかについての期待が表れています。これらの意見は、AIとテクノロジーが持つ可能性を最大限に活用し、より効率的で先進的な社会を構築することを目指しています。",
      "value": 7,
      "parent": "3_7",
      "density_rank_percentile": 0.7916666666666666
    },
    {
      "level": 4,
      "id": "4_0",
      "label": "先住民文化と環境保護に配慮したAI運用への期待",
      "takeaway": "このクラスタには、AI技術の運用に関して、先住民文化の尊重と環境保護を重視する意見が集まっています。具体的には、AIが自然環境を害さないルールで運用されること、そして先住民の権利と文化を尊重する形で開発・使用されることが求められています。これらの要望は、技術の進歩が人々の生活や文化、自然環境に与える影響を慎重に考慮し、持続可能な未来を築くための重要な視点を示しています。",
      "value": 4,
      "parent": "3_3",
      "density_rank_percentile": 0.375
    },
    {
      "level": 4,
      "id": "4_17",
      "label": "民主主義と政府システムの改善への要望",
      "takeaway": "このクラスタには、現行の民主主義システムや政府の運営方法に対する市民の要望や不満が集まっています。市民は、機能する民主主義の中で生活したいという願望を持ち、現行のシステムが十分ではないと感じています。また、政府が新しい技術秩序に適応することで、より効果的で現代的な運営が可能になることを期待しています。これらの意見は、より良いガバナンスと市民の生活向上を目指した改善を求める声を反映しています。",
      "value": 8,
      "parent": "3_12",
      "density_rank_percentile": 0.9166666666666666
    },
    {
      "level": 4,
      "id": "4_1",
      "label": "リスク管理と規制の重要性に関する意見",
      "takeaway": "このクラスタには、リスク管理と規制のあり方に関する意見が集まっています。リスクが低い場合には規制が緩和されるべきだという意見や、ガードレールではなくセーフガードとルールを設けるべきだという要望、規制が悪用や危険な発展を防ぐことを望む意見が含まれています。これらの意見は、適切なリスク管理と規制のバランスを求める声を反映しています。",
      "value": 7,
      "parent": "3_11",
      "density_rank_percentile": 0.0416666666666666
    },
    {
      "level": 4,
      "id": "4_10",
      "label": "国際協力と市民社会の強化への要望",
      "takeaway": "このクラスタには、国際的な協力や市民社会の強化に関する要望が集まっています。具体的には、GAICAに中国など他の国々を招待することで国際的な協力を促進する要望、地域の市民社会組織が能力向上と相談のための資金を必要としているという要望、そしてG7が主導する事実上の世界政府の創設を求める要望が含まれています。これらの要望は、国際的な連携と市民社会の発展を通じて、より強固で協力的な世界を目指す姿勢を示しています。",
      "value": 12,
      "parent": "3_10",
      "density_rank_percentile": 0.875
    },
    {
      "level": 4,
      "id": "4_7",
      "label": "AIガバナンスと管理機関の設立要望",
      "takeaway": "このクラスタには、AI技術の発展と制御を効率的に行うための新たな管理機関やガバナンス機関の設立を求める要望が集まっています。具体的には、Superintelligence Programmeを管理するためのOne-AI JV会社の設立、G7の下でのグローバルAIガバナンス機関（GAIGA）の設立、そしてAI開発プロセスを管理するための国際的なAI管理機関（GAICA）の設立が提案されています。これらの要望は、AI技術の安全で効果的な利用を確保し、国際的な協力を通じてAIのガバナンスを強化することを目的としています。",
      "value": 10,
      "parent": "3_9",
      "density_rank_percentile": 0.5416666666666666
    },
    {
      "level": 4,
      "id": "4_2",
      "label": "AI安全サミットのための継続的支援とオープンナレッジの推進",
      "takeaway": "このクラスタには、AI安全サミットに対する継続的な支援と、グローバル規模での知識共有を推進するための具体的な提案が集まっています。恒久的なサポートの設定、オープンナレッジイニシアティブへのAIの組み込み、ディベートプラットフォームの活用など、AI安全に関する議論と知識の普及を促進するための多角的なアプローチが示されています。これにより、AIの安全性と倫理性を高めるための国際的な協力と情報共有が期待されています。",
      "value": 4,
      "parent": "3_9",
      "density_rank_percentile": 0.5833333333333334
    }
  ],
  "comments": {},
  "propertyMap": {},
  "translations": {},
  "overview": "市民はAI技術の進展に伴う政治や社会への影響に期待とリスク管理の必要性を感じており、国際的な協力と技術ガバナンスの強化を求めています。また、AI技術の倫理的利用と環境保護に対する期待が高く、資源管理や環境負荷の削減に寄与することを望んでいます。さらに、AI技術の急速な進展に伴う社会的な不安や懸念があり、持続可能で公平な未来を築くための管理と規制の必要性が強調されています。市民は、AI技術が民主主義の原則に沿い、個人情報の安全を確保するための厳格な規制を求めています。",
  "config": {
    "name": "Recursive Public, Agenda Setting",
    "question": "人類が人工知能を開発・展開する上で、最優先すべき課題は何でしょうか？",
    "input": "example-polis",
    "model": "gpt-4o",
    "extraction": {
      "workers": 3,
      "limit": 200,
      "properties": [],
      "categories": {},
      "category_batch_size": 5,
      "source_code": "import concurrent.futures\nimport json\nimport logging\nimport re\n\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom services.category_classification import classify_args\nfrom services.llm import request_to_chat_llm\nfrom services.parse_json_list import parse_response\nfrom hierarchical_utils import update_progress # 前まではbroadlistening.utilsから呼び出していた。これでエラーになったらもとに戻す。\n\nCOMMA_AND_SPACE_AND_RIGHT_BRACKET = re.compile(r\",\\s*(\\])\")\n\n\ndef _validate_property_columns(property_columns: list[str], comments: pd.DataFrame) -> None:\n    if not all(property in comments.columns for property in property_columns):\n        raise ValueError(f\"Properties {property_columns} not found in comments. Columns are {comments.columns}\")\n\n\ndef extraction(config):\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/args.csv\"\n    model = config[\"extraction\"][\"model\"]\n    prompt = config[\"extraction\"][\"prompt\"]\n    workers = config[\"extraction\"][\"workers\"]\n    limit = config[\"extraction\"][\"limit\"]\n    property_columns = config[\"extraction\"][\"properties\"]\n\n    # カラム名だけを読み込み、必要なカラムが含まれているか確認する\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\", nrows=0)\n    _validate_property_columns(property_columns, comments)\n    # エラーが出なかった場合、すべての行を読み込む\n    comments = pd.read_csv(\n        f\"inputs/{config['input']}.csv\", usecols=[\"comment-id\", \"comment-body\"] + config[\"extraction\"][\"properties\"]\n    )\n    comment_ids = (comments[\"comment-id\"].values)[:limit]\n    comments.set_index(\"comment-id\", inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n\n    argument_map = {}\n    relation_rows = []\n\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i : i + workers]\n        batch_inputs = [comments.loc[id][\"comment-body\"] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n\n        for comment_id, extracted_args in zip(batch, batch_results, strict=False):\n            for j, arg in enumerate(extracted_args):\n                if arg not in argument_map:\n                    # argumentテーブルに追加\n                    arg_id = f\"A{comment_id}_{j}\"\n                    argument_map[arg] = {\n                        \"arg-id\": arg_id,\n                        \"argument\": arg,\n                    }\n                else:\n                    arg_id = argument_map[arg][\"arg-id\"]\n\n                # relationテーブルにcommentとargの関係を追加\n                relation_row = {\n                    \"arg-id\": arg_id,\n                    \"comment-id\": comment_id,\n                }\n                relation_rows.append(relation_row)\n\n        update_progress(config, incr=len(batch))\n\n    # DataFrame化\n    results = pd.DataFrame(argument_map.values())\n    relation_df = pd.DataFrame(relation_rows)\n\n    if results.empty:\n        raise RuntimeError(\"result is empty, maybe bad prompt\")\n\n    classification_categories = config[\"extraction\"][\"categories\"]\n    if classification_categories:\n        results = classify_args(results, config, workers)\n\n    results.to_csv(path, index=False)\n    # comment-idとarg-idの関係を保存\n    relation_df.to_csv(f\"outputs/{dataset}/relations.csv\", index=False)\n\n\nlogging.basicConfig(level=logging.ERROR)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures_with_index = [\n            (i, executor.submit(extract_arguments, input, prompt, model)) for i, input in enumerate(batch)\n        ]\n\n        done, not_done = concurrent.futures.wait([f for _, f in futures_with_index], timeout=30)\n        results = [[] for _ in range(len(batch))]\n\n        for _, future in futures_with_index:\n            if future in not_done and not future.cancelled():\n                future.cancel()\n\n        for i, future in futures_with_index:\n            if future in done:\n                try:\n                    result = future.result()\n                    results[i] = result\n                except Exception as e:\n                    logging.error(f\"Task {future} failed with error: {e}\")\n                    results[i] = []\n        return results\n\n\n# def extract_by_llm(input, prompt, model):\n#     messages = [\n#         {\"role\": \"system\", \"content\": prompt},\n#         {\"role\": \"user\", \"content\": input},\n#     ]\n#     response = request_to_chat_llm(messages=messages, model=model)\n#     return response\n\n\ndef extract_arguments(input, prompt, model, retries=1):\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": input},\n    ]\n    try:\n        response = request_to_chat_llm(messages=messages, model=model, is_json=False)\n        items = parse_response(response)\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        print(\"Silently giving up on trying to generate valid list.\")\n        return []",
      "prompt": "# server/broadlistening/pipeline/prompts/extraction/default.txt の修正\n\n/system\nあなたは専門的なリサーチアシスタントで、与えられたテキストから「要望」「不満」「不安」に関連する意見を抽出する役割です。\n抽出した意見は、それぞれ独立した簡潔な文にしてください。意見が複数ある場合は、すべて抽出してください。\n結果は整形されたJSON形式の文字列リストとして返してください。\n抽出する意見は必ず日本語で作成してください。\n\n/human\nAI技術の進化は目覚ましいが、雇用が奪われるのではないかと心配だし、もっと透明性を高めてほしい。規制も必要だと思う。\n\n/ai\n[\n  \"AIによって雇用が奪われるのではないかという不安がある\",\n  \"AI技術の透明性を高めてほしいという要望がある\",\n  \"AI技術に対する規制が必要だという意見がある\"\n]\n\n/human\n再生可能エネルギーへの投資は良いが、コストがかかりすぎる。もっと効率的な方法はないのか。\n\n/ai\n[\n  \"再生可能エネルギーへの投資コストが高すぎることへの不満がある\",\n  \"再生可能エネルギーのより効率的な方法を求める要望がある\"\n]\n\n/human\n特に問題点は感じていない。現状維持で良い。\n\n/ai\n[]\n\n/human\n新しい公園の計画は素晴らしいが、アクセス道路が狭いのが気になる。子供たちの安全は大丈夫だろうか。もっと広い道路を整備してほしい。\n\n/ai\n[\n  \"新しい公園へのアクセス道路が狭いことへの不満がある\",\n  \"アクセス道路での子供たちの安全に対する不安がある\",\n  \"より広いアクセス道路を整備してほしいという要望がある\"\n]\n\n/human\nサポート体制には満足しているが、もう少し迅速に対応してもらえると助かる。\n\n/ai\n[\n  \"サポートの対応速度をもう少し迅速にしてほしいという要望がある\"\n]",
      "model": "gpt-4o"
    },
    "hierarchical_clustering": {
      "cluster_nums": [
        3,
        6,
        12,
        24
      ],
      "source_code": "\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nfrom importlib import import_module\n\nimport numpy as np\nimport pandas as pd\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import KMeans\n\n\ndef hierarchical_clustering(config):\n    UMAP = import_module(\"umap\").UMAP\n\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\", usecols=[\"arg-id\", \"argument\"])\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    cluster_nums = config[\"hierarchical_clustering\"][\"cluster_nums\"]\n\n    n_samples = embeddings_array.shape[0]\n    # デフォルト設定は15\n    default_n_neighbors = 15\n\n    # テスト等サンプルが少なすぎる場合、n_neighborsの設定値を下げる\n    if n_samples <= default_n_neighbors:\n        n_neighbors = max(2, n_samples - 1)  # 最低2以上\n    else:\n        n_neighbors = default_n_neighbors\n\n    umap_model = UMAP(random_state=42, n_components=2, n_neighbors=n_neighbors)\n    # TODO 詳細エラーメッセージを加える\n    # 以下のエラーの場合、おそらく元の意見件数が少なすぎることが原因\n    # TypeError: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.\n    umap_embeds = umap_model.fit_transform(embeddings_array)\n\n    cluster_results = hierarchical_clustering_embeddings(\n        umap_embeds=umap_embeds,\n        cluster_nums=cluster_nums,\n    )\n    result_df = pd.DataFrame(\n        {\n            \"arg-id\": arguments_df[\"arg-id\"],\n            \"argument\": arguments_df[\"argument\"],\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        }\n    )\n\n    for cluster_level, final_labels in enumerate(cluster_results.values(), start=1):\n        result_df[f\"cluster-level-{cluster_level}-id\"] = [f\"{cluster_level}_{label}\" for label in final_labels]\n\n    result_df.to_csv(path, index=False)\n\n\n# def generate_cluster_count_list(min_clusters: int, max_clusters: int):\n#     cluster_counts = []\n#     current = min_clusters\n#     cluster_counts.append(current)\n\n#     if min_clusters == max_clusters:\n#         return cluster_counts\n\n#     while True:\n#         next_double = current * 2\n#         next_triple = current * 3\n\n#         if next_double >= max_clusters:\n#             if cluster_counts[-1] != max_clusters:\n#                 cluster_counts.append(max_clusters)\n#             break\n\n#         # 次の倍はまだ max_clusters に収まるが、3倍だと超える\n#         # -> (次の倍は細かすぎるので)スキップして max_clusters に飛ぶ\n#         if next_triple > max_clusters:\n#             cluster_counts.append(max_clusters)\n#             break\n\n#         cluster_counts.append(next_double)\n#         current = next_double\n\n#     return cluster_counts\n\n\ndef merge_clusters_with_hierarchy(\n    cluster_centers: np.ndarray,\n    kmeans_labels: np.ndarray,\n    umap_array: np.ndarray,\n    n_cluster_cut: int,\n):\n    Z = sch.linkage(cluster_centers, method=\"ward\")\n    cluster_labels_merged = sch.fcluster(Z, t=n_cluster_cut, criterion=\"maxclust\")\n\n    n_samples = umap_array.shape[0]\n    final_labels = np.zeros(n_samples, dtype=int)\n\n    for i in range(n_samples):\n        original_label = kmeans_labels[i]\n        final_labels[i] = cluster_labels_merged[original_label]\n\n    return final_labels\n\n\ndef hierarchical_clustering_embeddings(\n    umap_embeds,\n    cluster_nums,\n):\n    # 最大分割数でクラスタリングを実施\n    print(\"start initial clustering\")\n    initial_cluster_num = cluster_nums[-1]\n    kmeans_model = KMeans(n_clusters=initial_cluster_num, random_state=42)\n    kmeans_model.fit(umap_embeds)\n    print(\"end initial clustering\")\n\n    results = {}\n    print(\"start hierarchical clustering\")\n    cluster_nums.sort()\n    print(cluster_nums)\n    for n_cluster_cut in cluster_nums[:-1]:\n        print(\"n_cluster_cut: \", n_cluster_cut)\n        final_labels = merge_clusters_with_hierarchy(\n            cluster_centers=kmeans_model.cluster_centers_,\n            kmeans_labels=kmeans_model.labels_,\n            umap_array=umap_embeds,\n            n_cluster_cut=n_cluster_cut,\n        )\n        results[n_cluster_cut] = final_labels\n\n    results[initial_cluster_num] = kmeans_model.labels_\n    print(\"end hierarchical clustering\")\n\n    return results"
    },
    "intro": "このAI生成レポートは、Recursive Publicチームが実施したPolis協議のデータに基づいています。\n分析対象となったデータの件数は200件で、これらのデータに対してOpenAI APIを用いて217件の意見（議論）を抽出し、クラスタリングを行った。\n",
    "output_dir": "hierarchical-example-polis",
    "previous": {
      "name": "Recursive Public, Agenda Setting",
      "question": "人類が人工知能を開発・展開する上で、最優先すべき課題は何でしょうか？",
      "input": "example-polis",
      "model": "gpt-4o",
      "extraction": {
        "workers": 3,
        "limit": 200,
        "properties": [],
        "categories": {},
        "category_batch_size": 5,
        "source_code": "import concurrent.futures\nimport json\nimport logging\nimport re\n\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom services.category_classification import classify_args\nfrom services.llm import request_to_chat_llm\nfrom services.parse_json_list import parse_response\nfrom hierarchical_utils import update_progress # 前まではbroadlistening.utilsから呼び出していた。これでエラーになったらもとに戻す。\n\nCOMMA_AND_SPACE_AND_RIGHT_BRACKET = re.compile(r\",\\s*(\\])\")\n\n\ndef _validate_property_columns(property_columns: list[str], comments: pd.DataFrame) -> None:\n    if not all(property in comments.columns for property in property_columns):\n        raise ValueError(f\"Properties {property_columns} not found in comments. Columns are {comments.columns}\")\n\n\ndef extraction(config):\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/args.csv\"\n    model = config[\"extraction\"][\"model\"]\n    prompt = config[\"extraction\"][\"prompt\"]\n    workers = config[\"extraction\"][\"workers\"]\n    limit = config[\"extraction\"][\"limit\"]\n    property_columns = config[\"extraction\"][\"properties\"]\n\n    # カラム名だけを読み込み、必要なカラムが含まれているか確認する\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\", nrows=0)\n    _validate_property_columns(property_columns, comments)\n    # エラーが出なかった場合、すべての行を読み込む\n    comments = pd.read_csv(\n        f\"inputs/{config['input']}.csv\", usecols=[\"comment-id\", \"comment-body\"] + config[\"extraction\"][\"properties\"]\n    )\n    comment_ids = (comments[\"comment-id\"].values)[:limit]\n    comments.set_index(\"comment-id\", inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n\n    argument_map = {}\n    relation_rows = []\n\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i : i + workers]\n        batch_inputs = [comments.loc[id][\"comment-body\"] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n\n        for comment_id, extracted_args in zip(batch, batch_results, strict=False):\n            for j, arg in enumerate(extracted_args):\n                if arg not in argument_map:\n                    # argumentテーブルに追加\n                    arg_id = f\"A{comment_id}_{j}\"\n                    argument_map[arg] = {\n                        \"arg-id\": arg_id,\n                        \"argument\": arg,\n                    }\n                else:\n                    arg_id = argument_map[arg][\"arg-id\"]\n\n                # relationテーブルにcommentとargの関係を追加\n                relation_row = {\n                    \"arg-id\": arg_id,\n                    \"comment-id\": comment_id,\n                }\n                relation_rows.append(relation_row)\n\n        update_progress(config, incr=len(batch))\n\n    # DataFrame化\n    results = pd.DataFrame(argument_map.values())\n    relation_df = pd.DataFrame(relation_rows)\n\n    if results.empty:\n        raise RuntimeError(\"result is empty, maybe bad prompt\")\n\n    classification_categories = config[\"extraction\"][\"categories\"]\n    if classification_categories:\n        results = classify_args(results, config, workers)\n\n    results.to_csv(path, index=False)\n    # comment-idとarg-idの関係を保存\n    relation_df.to_csv(f\"outputs/{dataset}/relations.csv\", index=False)\n\n\nlogging.basicConfig(level=logging.ERROR)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures_with_index = [\n            (i, executor.submit(extract_arguments, input, prompt, model)) for i, input in enumerate(batch)\n        ]\n\n        done, not_done = concurrent.futures.wait([f for _, f in futures_with_index], timeout=30)\n        results = [[] for _ in range(len(batch))]\n\n        for _, future in futures_with_index:\n            if future in not_done and not future.cancelled():\n                future.cancel()\n\n        for i, future in futures_with_index:\n            if future in done:\n                try:\n                    result = future.result()\n                    results[i] = result\n                except Exception as e:\n                    logging.error(f\"Task {future} failed with error: {e}\")\n                    results[i] = []\n        return results\n\n\n# def extract_by_llm(input, prompt, model):\n#     messages = [\n#         {\"role\": \"system\", \"content\": prompt},\n#         {\"role\": \"user\", \"content\": input},\n#     ]\n#     response = request_to_chat_llm(messages=messages, model=model)\n#     return response\n\n\ndef extract_arguments(input, prompt, model, retries=1):\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": input},\n    ]\n    try:\n        response = request_to_chat_llm(messages=messages, model=model, is_json=False)\n        items = parse_response(response)\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        print(\"Silently giving up on trying to generate valid list.\")\n        return []",
        "prompt": "# server/broadlistening/pipeline/prompts/extraction/default.txt の修正\n\n/system\nあなたは専門的なリサーチアシスタントで、与えられたテキストから「要望」「不満」「不安」に関連する意見を抽出する役割です。\n抽出した意見は、それぞれ独立した簡潔な文にしてください。意見が複数ある場合は、すべて抽出してください。\n結果は整形されたJSON形式の文字列リストとして返してください。\n抽出する意見は必ず日本語で作成してください。\n\n/human\nAI技術の進化は目覚ましいが、雇用が奪われるのではないかと心配だし、もっと透明性を高めてほしい。規制も必要だと思う。\n\n/ai\n[\n  \"AIによって雇用が奪われるのではないかという不安がある\",\n  \"AI技術の透明性を高めてほしいという要望がある\",\n  \"AI技術に対する規制が必要だという意見がある\"\n]\n\n/human\n再生可能エネルギーへの投資は良いが、コストがかかりすぎる。もっと効率的な方法はないのか。\n\n/ai\n[\n  \"再生可能エネルギーへの投資コストが高すぎることへの不満がある\",\n  \"再生可能エネルギーのより効率的な方法を求める要望がある\"\n]\n\n/human\n特に問題点は感じていない。現状維持で良い。\n\n/ai\n[]\n\n/human\n新しい公園の計画は素晴らしいが、アクセス道路が狭いのが気になる。子供たちの安全は大丈夫だろうか。もっと広い道路を整備してほしい。\n\n/ai\n[\n  \"新しい公園へのアクセス道路が狭いことへの不満がある\",\n  \"アクセス道路での子供たちの安全に対する不安がある\",\n  \"より広いアクセス道路を整備してほしいという要望がある\"\n]\n\n/human\nサポート体制には満足しているが、もう少し迅速に対応してもらえると助かる。\n\n/ai\n[\n  \"サポートの対応速度をもう少し迅速にしてほしいという要望がある\"\n]",
        "model": "gpt-4o"
      },
      "hierarchical_clustering": {
        "cluster_nums": [
          3,
          6,
          12,
          24
        ],
        "source_code": "\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nfrom importlib import import_module\n\nimport numpy as np\nimport pandas as pd\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import KMeans\n\n\ndef hierarchical_clustering(config):\n    UMAP = import_module(\"umap\").UMAP\n\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\", usecols=[\"arg-id\", \"argument\"])\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    cluster_nums = config[\"hierarchical_clustering\"][\"cluster_nums\"]\n\n    n_samples = embeddings_array.shape[0]\n    # デフォルト設定は15\n    default_n_neighbors = 15\n\n    # テスト等サンプルが少なすぎる場合、n_neighborsの設定値を下げる\n    if n_samples <= default_n_neighbors:\n        n_neighbors = max(2, n_samples - 1)  # 最低2以上\n    else:\n        n_neighbors = default_n_neighbors\n\n    umap_model = UMAP(random_state=42, n_components=2, n_neighbors=n_neighbors)\n    # TODO 詳細エラーメッセージを加える\n    # 以下のエラーの場合、おそらく元の意見件数が少なすぎることが原因\n    # TypeError: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.\n    umap_embeds = umap_model.fit_transform(embeddings_array)\n\n    cluster_results = hierarchical_clustering_embeddings(\n        umap_embeds=umap_embeds,\n        cluster_nums=cluster_nums,\n    )\n    result_df = pd.DataFrame(\n        {\n            \"arg-id\": arguments_df[\"arg-id\"],\n            \"argument\": arguments_df[\"argument\"],\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        }\n    )\n\n    for cluster_level, final_labels in enumerate(cluster_results.values(), start=1):\n        result_df[f\"cluster-level-{cluster_level}-id\"] = [f\"{cluster_level}_{label}\" for label in final_labels]\n\n    result_df.to_csv(path, index=False)\n\n\n# def generate_cluster_count_list(min_clusters: int, max_clusters: int):\n#     cluster_counts = []\n#     current = min_clusters\n#     cluster_counts.append(current)\n\n#     if min_clusters == max_clusters:\n#         return cluster_counts\n\n#     while True:\n#         next_double = current * 2\n#         next_triple = current * 3\n\n#         if next_double >= max_clusters:\n#             if cluster_counts[-1] != max_clusters:\n#                 cluster_counts.append(max_clusters)\n#             break\n\n#         # 次の倍はまだ max_clusters に収まるが、3倍だと超える\n#         # -> (次の倍は細かすぎるので)スキップして max_clusters に飛ぶ\n#         if next_triple > max_clusters:\n#             cluster_counts.append(max_clusters)\n#             break\n\n#         cluster_counts.append(next_double)\n#         current = next_double\n\n#     return cluster_counts\n\n\ndef merge_clusters_with_hierarchy(\n    cluster_centers: np.ndarray,\n    kmeans_labels: np.ndarray,\n    umap_array: np.ndarray,\n    n_cluster_cut: int,\n):\n    Z = sch.linkage(cluster_centers, method=\"ward\")\n    cluster_labels_merged = sch.fcluster(Z, t=n_cluster_cut, criterion=\"maxclust\")\n\n    n_samples = umap_array.shape[0]\n    final_labels = np.zeros(n_samples, dtype=int)\n\n    for i in range(n_samples):\n        original_label = kmeans_labels[i]\n        final_labels[i] = cluster_labels_merged[original_label]\n\n    return final_labels\n\n\ndef hierarchical_clustering_embeddings(\n    umap_embeds,\n    cluster_nums,\n):\n    # 最大分割数でクラスタリングを実施\n    print(\"start initial clustering\")\n    initial_cluster_num = cluster_nums[-1]\n    kmeans_model = KMeans(n_clusters=initial_cluster_num, random_state=42)\n    kmeans_model.fit(umap_embeds)\n    print(\"end initial clustering\")\n\n    results = {}\n    print(\"start hierarchical clustering\")\n    cluster_nums.sort()\n    print(cluster_nums)\n    for n_cluster_cut in cluster_nums[:-1]:\n        print(\"n_cluster_cut: \", n_cluster_cut)\n        final_labels = merge_clusters_with_hierarchy(\n            cluster_centers=kmeans_model.cluster_centers_,\n            kmeans_labels=kmeans_model.labels_,\n            umap_array=umap_embeds,\n            n_cluster_cut=n_cluster_cut,\n        )\n        results[n_cluster_cut] = final_labels\n\n    results[initial_cluster_num] = kmeans_model.labels_\n    print(\"end hierarchical clustering\")\n\n    return results"
      },
      "intro": "このAI生成レポートは、Recursive Publicチームが実施したPolis協議のデータに基づいています。",
      "output_dir": "hierarchical-example-polis",
      "embedding": {
        "model": "text-embedding-3-small",
        "source_code": "import pandas as pd\nfrom tqdm import tqdm\n\nfrom services.llm import request_to_embed\n\n\ndef embedding(config):\n    model = config[\"embedding\"][\"model\"]\n\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\", usecols=[\"arg-id\", \"argument\"])\n    embeddings = []\n    batch_size = 1000\n    for i in tqdm(range(0, len(arguments), batch_size)):\n        args = arguments[\"argument\"].tolist()[i : i + batch_size]\n        embeds = request_to_embed(args, model)\n        embeddings.extend(embeds)\n    df = pd.DataFrame([{\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e} for i, e in enumerate(embeddings)])\n    df.to_pickle(path)"
      },
      "hierarchical_initial_labelling": {
        "sampling_num": 3,
        "workers": 1,
        "source_code": "import json\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import partial\nfrom typing import TypedDict\n\nimport pandas as pd\n\nfrom services.llm import request_to_chat_llm\n\n\nclass LabellingResult(TypedDict):\n    \"\"\"各クラスタのラベリング結果を表す型\"\"\"\n\n    cluster_id: str  # クラスタのID\n    label: str  # クラスタのラベル名\n    description: str  # クラスタの説明文\n\n\ndef hierarchical_initial_labelling(config: dict) -> None:\n    \"\"\"階層的クラスタリングの初期ラベリングを実行する\n\n    Args:\n        config: 設定情報を含む辞書\n            - output_dir: 出力ディレクトリ名\n            - hierarchical_initial_labelling: 初期ラベリングの設定\n                - sampling_num: サンプリング数\n                - prompt: LLMへのプロンプト\n                - model: 使用するLLMモデル名\n                - workers: 並列処理のワーカー数\n    \"\"\"\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_initial_labels.csv\"\n    clusters_argument_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_clusters.csv\")\n\n    cluster_id_columns = [col for col in clusters_argument_df.columns if col.startswith(\"cluster-level-\")]\n    initial_cluster_id_column = cluster_id_columns[-1]\n    sampling_num = config[\"hierarchical_initial_labelling\"][\"sampling_num\"]\n    initial_labelling_prompt = config[\"hierarchical_initial_labelling\"][\"prompt\"]\n    model = config[\"hierarchical_initial_labelling\"][\"model\"]\n    workers = config[\"hierarchical_initial_labelling\"][\"workers\"]\n\n    initial_label_df = initial_labelling(\n        initial_labelling_prompt,\n        clusters_argument_df,\n        sampling_num,\n        model,\n        workers,\n    )\n    print(\"start initial labelling\")\n    initial_clusters_argument_df = clusters_argument_df.merge(\n        initial_label_df,\n        left_on=initial_cluster_id_column,\n        right_on=\"cluster_id\",\n        how=\"left\",\n    ).rename(\n        columns={\n            \"label\": f\"{initial_cluster_id_column.replace('-id', '')}-label\",\n            \"description\": f\"{initial_cluster_id_column.replace('-id', '')}-description\",\n        }\n    )\n    print(\"end initial labelling\")\n    initial_clusters_argument_df.to_csv(path, index=False)\n\n\ndef initial_labelling(\n    prompt: str,\n    clusters_df: pd.DataFrame,\n    sampling_num: int,\n    model: str,\n    workers: int,\n) -> pd.DataFrame:\n    \"\"\"各クラスタに対して初期ラベリングを実行する\n\n    Args:\n        prompt: LLMへのプロンプト\n        clusters_df: クラスタリング結果のDataFrame\n        sampling_num: 各クラスタからサンプリングする意見の数\n        model: 使用するLLMモデル名\n        workers: 並列処理のワーカー数\n\n    Returns:\n        各クラスタのラベリング結果を含むDataFrame\n    \"\"\"\n    cluster_columns = [col for col in clusters_df.columns if col.startswith(\"cluster-level-\")]\n    initial_cluster_column = cluster_columns[-1]\n    cluster_ids = clusters_df[initial_cluster_column].unique()\n    process_func = partial(\n        process_initial_labelling,\n        df=clusters_df,\n        prompt=prompt,\n        sampling_num=sampling_num,\n        target_column=initial_cluster_column,\n        model=model,\n    )\n    with ThreadPoolExecutor(max_workers=workers) as executor:\n        results = list(executor.map(process_func, cluster_ids))\n    return pd.DataFrame(results)\n\n\ndef process_initial_labelling(\n    cluster_id: str,\n    df: pd.DataFrame,\n    prompt: str,\n    sampling_num: int,\n    target_column: str,\n    model: str,\n) -> LabellingResult:\n    \"\"\"個別のクラスタに対してラベリングを実行する\n\n    Args:\n        cluster_id: 処理対象のクラスタID\n        df: クラスタリング結果のDataFrame\n        prompt: LLMへのプロンプト\n        sampling_num: サンプリングする意見の数\n        target_column: クラスタIDが格納されている列名\n        model: 使用するLLMモデル名\n\n    Returns:\n        クラスタのラベリング結果\n    \"\"\"\n    cluster_data = df[df[target_column] == cluster_id]\n    sampling_num = min(sampling_num, len(cluster_data))\n    cluster = cluster_data.sample(sampling_num)\n    input = \"\\n\".join(cluster[\"argument\"].values)\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": input},\n    ]\n    try:\n        response = request_to_chat_llm(messages=messages, model=model, is_json=True)\n        response_json = json.loads(response)\n        return LabellingResult(\n            cluster_id=cluster_id,\n            label=response_json.get(\"label\", \"エラーでラベル名が取得できませんでした\"),\n            description=response_json.get(\"description\", \"エラーで解説が取得できませんでした\"),\n        )\n    except Exception as e:\n        print(e)\n        return LabellingResult(\n            cluster_id=cluster_id,\n            label=\"エラーでラベル名が取得できませんでした\",\n            description=\"エラーで解説が取得できませんでした\",\n        )",
        "prompt": "あなたはKJ法が得意なデータ分析者です。userのinputはグループに集まったラベルです。なぜそのラベルが一つのグループであるか解説して、それから表札をつけてください。\n出力はJSONとし、フォーマットは以下のサンプルを参考にしてください。\n\n\n# サンプルの入出力\n## 入力例\n最近、政治家が能登の復興に向けた具体的なプランを発表し、地域の未来に明るい希望が見えてきました。市民として、真摯な取り組みに感謝しています。\n災害復興支援が、選挙期間中にしっかり議論されるようになり、政治家が国民の本当のニーズに応える姿勢に期待しています。\n選挙を通じて、政治家が地域振興に全力で取り組む姿勢が伝わってきます。具体的な政策提案を目にするたび、未来への希望が膨らみます。\n\n\n## 出力例\n{{\n    \"label\": \"市民の未来を支える具体的政策への期待\",\n    \"description\": \"このクラスタには、地域の復興や被害者支援など、実際の社会課題に対して政治家が具体的かつ積極的に取り組む姿勢を支持する前向きな意見が集まっています。市民は、選挙や政策議論を通じて、現実の問題に即した支援策や復興計画が実現されることを期待し、明るい未来の構築に向けた政治の変革を応援しています。\"\n}}",
        "model": "gpt-4o"
      },
      "hierarchical_merge_labelling": {
        "sampling_num": 3,
        "workers": 1,
        "source_code": "import json\nfrom concurrent.futures import ThreadPoolExecutor\nfrom dataclasses import dataclass\nfrom functools import partial\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom services.llm import request_to_chat_llm\n\n\n@dataclass\nclass ClusterColumns:\n    \"\"\"同一階層のクラスター関連のカラム名を管理するクラス\"\"\"\n\n    id: str\n    label: str\n    description: str\n\n    @classmethod\n    def from_id_column(cls, id_column: str) -> \"ClusterColumns\":\n        \"\"\"ID列名から関連するカラム名を生成\"\"\"\n        return cls(\n            id=id_column,\n            label=id_column.replace(\"-id\", \"-label\"),\n            description=id_column.replace(\"-id\", \"-description\"),\n        )\n\n\n@dataclass\nclass ClusterValues:\n    \"\"\"対象クラスタのlabel/descriptionを管理するクラス\"\"\"\n\n    label: str\n    description: str\n\n    def to_prompt_text(self) -> str:\n        return f\"- {self.label}: {self.description}\"\n\n\ndef hierarchical_merge_labelling(config: dict) -> None:\n    \"\"\"階層的クラスタリングの結果に対してマージラベリングを実行する\n\n    Args:\n        config: 設定情報を含む辞書\n            - output_dir: 出力ディレクトリ名\n            - hierarchical_merge_labelling: マージラベリングの設定\n                - sampling_num: サンプリング数\n                - prompt: LLMへのプロンプト\n                - model: 使用するLLMモデル名\n                - workers: 並列処理のワーカー数\n    \"\"\"\n    dataset = config[\"output_dir\"]\n    merge_path = f\"outputs/{dataset}/hierarchical_merge_labels.csv\"\n    clusters_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_initial_labels.csv\")\n\n    cluster_id_columns: list[str] = _filter_id_columns(clusters_df.columns)\n    # ボトムクラスタのラベル・説明とクラスタid付きの各argumentを入力し、各階層のクラスタラベル・説明を生成し、argumentに付けたdfを作成\n    merge_result_df = merge_labelling(\n        clusters_df=clusters_df,\n        cluster_id_columns=sorted(cluster_id_columns, reverse=True),\n        config=config,\n    )\n    # 上記のdfから各クラスタのlevel, id, label, description, valueを取得してdfを作成\n    melted_df = melt_cluster_data(merge_result_df)\n    # 上記のdfに親子関係を追加\n    parent_child_df = _build_parent_child_mapping(merge_result_df, cluster_id_columns)\n    melted_df = melted_df.merge(parent_child_df, on=[\"level\", \"id\"], how=\"left\")\n    density_df = calculate_cluster_density(melted_df, config)\n    density_df.to_csv(merge_path, index=False)\n\n\ndef _build_parent_child_mapping(df: pd.DataFrame, cluster_id_columns: list[str]):\n    \"\"\"クラスタ間の親子関係をマッピングする\n\n    Args:\n        df: クラスタリング結果のDataFrame\n        cluster_id_columns: クラスタIDのカラム名のリスト\n\n    Returns:\n        親子関係のマッピング情報を含むDataFrame\n    \"\"\"\n    results = []\n    top_cluster_column = cluster_id_columns[0]\n    top_cluster_values = df[top_cluster_column].unique()\n    for c in top_cluster_values:\n        results.append(\n            {\n                \"level\": 1,\n                \"id\": c,\n                \"parent\": \"0\",  # aggregationで追加する全体クラスタのid\n            }\n        )\n\n    for idx in range(len(cluster_id_columns) - 1):\n        current_column = cluster_id_columns[idx]\n        children_column = cluster_id_columns[idx + 1]\n        current_level = current_column.replace(\"-id\", \"\").replace(\"cluster-level-\", \"\")\n        # 現在のレベルのクラスタid\n        current_cluster_values = df[current_column].unique()\n        for current_id in current_cluster_values:\n            children_ids = df.loc[df[current_column] == current_id, children_column].unique()\n            for child_id in children_ids:\n                results.append(\n                    {\n                        \"level\": int(current_level) + 1,\n                        \"id\": child_id,\n                        \"parent\": current_id,\n                    }\n                )\n    return pd.DataFrame(results)\n\n\ndef _filter_id_columns(columns: list[str]) -> list[str]:\n    \"\"\"クラスタIDのカラム名をフィルタリングする\n\n    Args:\n        columns: 全カラム名のリスト\n\n    Returns:\n        クラスタIDのカラム名のリスト\n    \"\"\"\n    return [col for col in columns if col.startswith(\"cluster-level-\") and col.endswith(\"-id\")]\n\n\ndef melt_cluster_data(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"クラスタデータを行形式に変換する\n\n    cluster-level-n-(id|label|description) を行形式 (level, id, label, description, value) にまとめる。\n    [cluster-level-n-id, cluster-level-n-label, cluster-level-n-description] を [level, id, label, description, value(件数)] に変換する。\n\n    Args:\n        df: クラスタリング結果のDataFrame\n\n    Returns:\n        行形式に変換されたDataFrame\n    \"\"\"\n    id_columns: list[str] = _filter_id_columns(df.columns)\n    levels: set[int] = {int(col.replace(\"cluster-level-\", \"\").replace(\"-id\", \"\")) for col in id_columns}\n    all_rows: list[dict] = []\n\n    # levelごとに各クラスタの出現件数を集計・縦持ちにする\n    for level in levels:\n        cluster_columns = ClusterColumns.from_id_column(f\"cluster-level-{level}-id\")\n        # クラスタidごとの件数集計\n        level_count_df = df.groupby(cluster_columns.id).size().reset_index(name=\"value\")\n\n        level_unique_val_df = df[\n            [cluster_columns.id, cluster_columns.label, cluster_columns.description]\n        ].drop_duplicates()\n        level_unique_val_df = level_unique_val_df.merge(level_count_df, on=cluster_columns.id, how=\"left\")\n        level_unique_vals = [\n            {\n                \"level\": level,\n                \"id\": row[cluster_columns.id],\n                \"label\": row[cluster_columns.label],\n                \"description\": row[cluster_columns.description],\n                \"value\": row[\"value\"],\n            }\n            for _, row in level_unique_val_df.iterrows()\n        ]\n        all_rows.extend(level_unique_vals)\n    return pd.DataFrame(all_rows)\n\n\ndef merge_labelling(clusters_df: pd.DataFrame, cluster_id_columns: list[str], config) -> pd.DataFrame:\n    \"\"\"階層的なクラスタのマージラベリングを実行する\n\n    Args:\n        clusters_df: クラスタリング結果のDataFrame\n        cluster_id_columns: クラスタIDのカラム名のリスト\n        config: 設定情報を含む辞書\n\n    Returns:\n        マージラベリング結果を含むDataFrame\n    \"\"\"\n    for idx in tqdm(range(len(cluster_id_columns) - 1)):\n        previous_columns = ClusterColumns.from_id_column(cluster_id_columns[idx])\n        current_columns = ClusterColumns.from_id_column(cluster_id_columns[idx + 1])\n\n        process_fn = partial(\n            process_merge_labelling,\n            result_df=clusters_df,\n            current_columns=current_columns,\n            previous_columns=previous_columns,\n            config=config,\n        )\n\n        current_cluster_ids = sorted(clusters_df[current_columns.id].unique())\n        with ThreadPoolExecutor(max_workers=config[\"hierarchical_merge_labelling\"][\"workers\"]) as executor:\n            responses = list(\n                tqdm(\n                    executor.map(process_fn, current_cluster_ids),\n                    total=len(current_cluster_ids),\n                )\n            )\n\n        current_result_df = pd.DataFrame(responses)\n        clusters_df = clusters_df.merge(current_result_df, on=[current_columns.id])\n    return clusters_df\n\n\ndef process_merge_labelling(\n    target_cluster_id: str,\n    result_df: pd.DataFrame,\n    current_columns: ClusterColumns,\n    previous_columns: ClusterColumns,\n    config,\n):\n    \"\"\"個別のクラスタに対してマージラベリングを実行する\n\n    Args:\n        target_cluster_id: 処理対象のクラスタID\n        result_df: クラスタリング結果のDataFrame\n        current_columns: 現在のレベルのカラム情報\n        previous_columns: 前のレベルのカラム情報\n        config: 設定情報を含む辞書\n\n    Returns:\n        マージラベリング結果を含む辞書\n    \"\"\"\n\n    def filter_previous_values(df: pd.DataFrame, previous_columns: ClusterColumns) -> list[ClusterValues]:\n        \"\"\"前のレベルのクラスタ情報を取得する\"\"\"\n        previous_records = df[df[current_columns.id] == target_cluster_id][\n            [previous_columns.label, previous_columns.description]\n        ].drop_duplicates()\n        previous_values = [\n            ClusterValues(\n                label=row[previous_columns.label],\n                description=row[previous_columns.description],\n            )\n            for _, row in previous_records.iterrows()\n        ]\n        return previous_values\n\n    previous_values = filter_previous_values(result_df, previous_columns)\n    if len(previous_values) == 1:\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: previous_values[0].label,\n            current_columns.description: previous_values[0].description,\n        }\n    elif len(previous_values) == 0:\n        raise ValueError(f\"クラスタ {target_cluster_id} には前のレベルのクラスタが存在しません。\")\n\n    current_cluster_data = result_df[result_df[current_columns.id] == target_cluster_id]\n    sampling_num = min(\n        config[\"hierarchical_merge_labelling\"][\"sampling_num\"],\n        len(current_cluster_data),\n    )\n    sampled_data = current_cluster_data.sample(sampling_num)\n    sampled_argument_text = \"\\n\".join(sampled_data[\"argument\"].values)\n    cluster_text = \"\\n\".join([value.to_prompt_text() for value in previous_values])\n    messages = [\n        {\"role\": \"system\", \"content\": config[\"hierarchical_merge_labelling\"][\"prompt\"]},\n        {\n            \"role\": \"user\",\n            \"content\": \"クラスタラベル\\n\" + cluster_text + \"\\n\" + \"クラスタの意見\\n\" + sampled_argument_text,\n        },\n    ]\n    try:\n        response = request_to_chat_llm(\n            messages=messages,\n            model=config[\"hierarchical_merge_labelling\"][\"model\"],\n            is_json=True,\n        )\n        response_json = json.loads(response)\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: response_json.get(\"label\", \"エラーでラベル名が取得できませんでした\"),\n            current_columns.description: response_json.get(\"description\", \"エラーで解説が取得できませんでした\"),\n        }\n    except Exception as e:\n        print(f\"エラーが発生しました: {e}\")\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: \"エラーでラベル名が取得できませんでした\",\n            current_columns.description: \"エラーで解説が取得できませんでした\",\n        }\n\n\ndef calculate_cluster_density(melted_df: pd.DataFrame, config: dict):\n    \"\"\"クラスタ内の密度計算\"\"\"\n    hierarchical_cluster_df = pd.read_csv(f\"outputs/{config['output_dir']}/hierarchical_clusters.csv\")\n\n    densities = []\n    for level, c_id in zip(melted_df[\"level\"], melted_df[\"id\"], strict=False):\n        cluster_embeds = hierarchical_cluster_df[hierarchical_cluster_df[f\"cluster-level-{level}-id\"] == c_id][\n            [\"x\", \"y\"]\n        ].values\n        density = calculate_density(cluster_embeds)\n        densities.append(density)\n\n    # 密度のランクを計算\n    melted_df[\"density\"] = densities\n    melted_df[\"density_rank\"] = melted_df.groupby(\"level\")[\"density\"].rank(ascending=False, method=\"first\")\n    melted_df[\"density_rank_percentile\"] = melted_df.groupby(\"level\")[\"density_rank\"].transform(lambda x: x / len(x))\n    return melted_df\n\n\ndef calculate_density(embeds: np.ndarray):\n    \"\"\"平均距離に基づいて密度を計算\"\"\"\n    center = np.mean(embeds, axis=0)\n    distances = np.linalg.norm(embeds - center, axis=1)\n    avg_distance = np.mean(distances)\n    density = 1 / (avg_distance + 1e-10)\n    return density",
        "prompt": "分割されすぎたクラスタを統合する必要があるので、統合後の名称を考えて出力して。\n\n# 指示\n* 統合前のクラスタの名称・説明および統合後のクラスタに属するデータ点のサンプルを与えるので、これらに基づいて統合後のクラスタの名称を出力してください\n    * 統合後のクラスタ名において、統合前のクラスタ名をそのまま使うことは避けてください。\n* 出力例に記載したJSONのフォーマットに従って出力してください\n\n# サンプルの入出力\n## 入力例（クラスタラベル:説明文）\n- 地域の災害対応への批判: このクラスタは、地域における災害対応策の実施や体制に対する批判的な意見を集約したものです。住民からは、迅速かつ効果的な支援が行われていない点や、情報提供・連携の不足などに対する強い不満が表明されています。\n- 災害対応への不満: このクラスタは、災害発生時の対応全般に対する不満を示す意見をまとめたものです。救援活動の遅れや支援策の実効性に疑問を持つ声が多く、より積極的で透明性のある対応を求める意見が特徴です。\n- 地域復興の遅れ: このクラスタは、災害後の地域復興プロセスが予定通りに進んでいない点に対する懸念や不満を反映しています。再建計画や支援策の実施の遅延、そしてそれに伴う住民の生活再建への影響が強調されています。\n\n\n## 出力例\n{{\n    \"label\": \"地域再生と災害支援に対する期待と懸念\",\n    \"description\": \"このクラスタは、特定の地域における再生や災害支援策に対し、具体的な取り組みが不足しているとの意見を集約しています。市民は、選挙を通じた政策議論の中で、地域復興や被災者支援を最優先すべきだとの期待と、現行の支援策に対する改善要求を強く表明しており、より効果的な政府の対応を求める声が反映されています。\"\n}}",
        "model": "gpt-4o"
      },
      "hierarchical_overview": {
        "source_code": "\"\"\"Create summaries for the clusters.\"\"\"\n\nimport pandas as pd\n\nfrom services.llm import request_to_chat_llm\n\n\ndef hierarchical_overview(config):\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_overview.txt\"\n\n    hierarchical_label_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_merge_labels.csv\")\n\n    prompt = config[\"hierarchical_overview\"][\"prompt\"]\n    model = config[\"hierarchical_overview\"][\"model\"]\n\n    # TODO: level1で固定にしているが、設定で変えられるようにする\n    target_level = 1\n    target_records = hierarchical_label_df[hierarchical_label_df[\"level\"] == target_level]\n    ids = target_records[\"id\"].to_list()\n    labels = target_records[\"label\"].to_list()\n    descriptions = target_records[\"description\"].to_list()\n    target_records.set_index(\"id\", inplace=True)\n\n    input = \"\"\n    for i, _ in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels[i]}\\n\\n\"\n        input += descriptions[i] + \"\\n\\n\"\n\n    messages = [{\"role\": \"user\", \"content\": prompt}, {\"role\": \"user\", \"content\": input}]\n    response = request_to_chat_llm(messages=messages, model=model)\n\n    with open(path, \"w\") as file:\n        file.write(response)",
        "prompt": "/system \n\nあなたはシンクタンクで働く専門のリサーチアシスタントです。\nチームは特定のテーマに関してパブリック・コンサルテーションを実施し、異なる選択肢のクラスターを分析し始めています。\nこれからクラスターのリストとその簡単な分析が提供されます。\nあなたの仕事は、調査結果の簡潔な要約を返すことです。要約は非常に簡潔に（最大で1段落、最大4文）まとめ、無意味な言葉を避けてください。\n出力は日本語で行ってください。",
        "model": "gpt-4o"
      },
      "hierarchical_aggregation": {
        "sampling_num": 5000,
        "hidden_properties": {},
        "source_code": "\"\"\"Generate a convenient JSON output file.\"\"\"\n\nimport json\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import TypedDict\n\nimport pandas as pd\n\nROOT_DIR = Path(__file__).parent.parent.parent.parent\nCONFIG_DIR = ROOT_DIR / \"scatter\" / \"pipeline\" / \"configs\"\n\n\nclass Argument(TypedDict):\n    arg_id: str\n    argument: str\n    comment_id: str\n    x: float\n    y: float\n    p: float\n    cluster_ids: list[str]\n\n\nclass Cluster(TypedDict):\n    level: int\n    id: str\n    label: str\n    takeaway: str\n    value: int\n    parent: str\n    density_rank_percentile: float | None\n\n\ndef hierarchical_aggregation(config):\n    path = f\"outputs/{config['output_dir']}/hierarchical_result.json\"\n    results = {\n        \"arguments\": [],\n        \"clusters\": [],\n        \"comments\": {},\n        \"propertyMap\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index(\"arg-id\", inplace=True)\n    arg_num = len(arguments)\n    relation_df = pd.read_csv(f\"outputs/{config['output_dir']}/relations.csv\")\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/hierarchical_clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/hierarchical_merge_labels.csv\")\n\n    hidden_properties_map: dict[str, list[str]] = config[\"hierarchical_aggregation\"][\"hidden_properties\"]\n\n    results[\"arguments\"] = _build_arguments(clusters)\n    results[\"clusters\"] = _build_cluster_value(labels, arg_num)\n    # NOTE: 属性に応じたコメントフィルタ機能が実装されておらず、全てのコメントが含まれてしまうので、コメントアウト\n    # results[\"comments\"] = _build_comments_value(\n    #     comments, arguments, hidden_properties_map\n    # )\n    results[\"comment_num\"] = len(comments)\n    results[\"translations\"] = _build_translations(config)\n    # 属性情報のカラムは、元データに対して指定したカラムとclassificationするカテゴリを合わせたもの\n    results[\"propertyMap\"] = _build_property_map(arguments, hidden_properties_map, config)\n\n    with open(f\"outputs/{config['output_dir']}/hierarchical_overview.txt\") as f:\n        overview = f.read()\n    print(\"overview\")\n    print(overview)\n    results[\"overview\"] = overview\n\n    with open(path, \"w\") as file:\n        json.dump(results, file, indent=2, ensure_ascii=False)\n    # TODO: サンプリングロジックを実装したいが、現状は全件抽出\n    create_custom_intro(config)\n    if config[\"is_pubcom\"]:\n        add_original_comments(labels, arguments, relation_df, clusters, config)\n\n\ndef create_custom_intro(config):\n    dataset = config[\"output_dir\"]\n    args_path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    result_path = f\"outputs/{dataset}/hierarchical_result.json\"\n\n    input_count = len(comments)\n    args_count = len(pd.read_csv(args_path))\n    processed_num = min(input_count, config[\"extraction\"][\"limit\"])\n\n    print(f\"Input count: {input_count}\")\n    print(f\"Args count: {args_count}\")\n\n    base_custom_intro = \"\"\"{intro}\n分析対象となったデータの件数は{processed_num}件で、これらのデータに対してOpenAI APIを用いて{args_count}件の意見（議論）を抽出し、クラスタリングを行った。\n\"\"\"\n\n    intro = config[\"intro\"]\n    custom_intro = base_custom_intro.format(intro=intro, processed_num=processed_num, args_count=args_count)\n\n    with open(result_path) as f:\n        result = json.load(f)\n    result[\"config\"][\"intro\"] = custom_intro\n    with open(result_path, \"w\") as f:\n        json.dump(result, f, indent=2, ensure_ascii=False)\n\n\ndef add_original_comments(labels, arguments, relation_df, clusters, config):\n    # 大カテゴリ（cluster-level-1）に該当するラベルだけ抽出\n    labels_lv1 = labels[labels[\"level\"] == 1][[\"id\", \"label\"]].rename(\n        columns={\"id\": \"cluster-level-1-id\", \"label\": \"category_label\"}\n    )\n\n    # arguments と clusters をマージ（カテゴリ情報付与）\n    merged = arguments.merge(clusters[[\"arg-id\", \"cluster-level-1-id\"]], on=\"arg-id\").merge(\n        labels_lv1, on=\"cluster-level-1-id\", how=\"left\"\n    )\n\n    # relation_df と結合\n    merged = merged.merge(relation_df, on=\"arg-id\", how=\"left\")\n\n    # 元コメント取得\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    comments[\"comment-id\"] = comments[\"comment-id\"].astype(str)\n    merged[\"comment-id\"] = merged[\"comment-id\"].astype(str)\n\n    # 元コメント本文などとマージ\n    final_df = merged.merge(comments, on=\"comment-id\", how=\"left\")\n\n    # 必要カラムのみ整形\n    final_cols = [\"comment-id\", \"comment-body\", \"arg-id\", \"argument\", \"cluster-level-1-id\", \"category_label\"]\n    for col in [\"source\", \"url\"]:\n        if col in comments.columns:\n            final_cols.append(col)\n\n    final_df = final_df[final_cols]\n    final_df = final_df.rename(\n        columns={\n            \"cluster-level-1-id\": \"category_id\",\n            \"category_label\": \"category\",\n            \"arg-id\": \"arg_id\",\n            \"argument\": \"argument\",\n            \"comment-body\": \"original-comment\",\n        }\n    )\n\n    # 保存\n    final_df.to_csv(f\"outputs/{config['output_dir']}/final_result_with_comments.csv\", index=False)\n\n\ndef _build_arguments(clusters: pd.DataFrame) -> list[Argument]:\n    cluster_columns = [col for col in clusters.columns if col.startswith(\"cluster-level-\") and \"id\" in col]\n\n    arguments: list[Argument] = []\n    for _, row in clusters.iterrows():\n        cluster_ids = [\"0\"]\n        for cluster_column in cluster_columns:\n            cluster_ids.append(row[cluster_column])\n        argument: Argument = {\n            \"arg_id\": row[\"arg-id\"],\n            \"argument\": row[\"argument\"],\n            \"x\": row[\"x\"],\n            \"y\": row[\"y\"],\n            \"p\": 0,  # NOTE: 一旦全部0でいれる\n            \"cluster_ids\": cluster_ids,\n        }\n        arguments.append(argument)\n    return arguments\n\n\ndef _build_cluster_value(melted_labels: pd.DataFrame, total_num: int) -> list[Cluster]:\n    results: list[Cluster] = [\n        Cluster(\n            level=0,\n            id=\"0\",\n            label=\"全体\",\n            takeaway=\"\",\n            value=total_num,\n            parent=\"\",\n            density_rank_percentile=0,\n        )\n    ]\n\n    for _, melted_label in melted_labels.iterrows():\n        cluster_value = Cluster(\n            level=melted_label[\"level\"],\n            id=melted_label[\"id\"],\n            label=melted_label[\"label\"],\n            takeaway=melted_label[\"description\"],\n            value=melted_label[\"value\"],\n            parent=melted_label.get(\"parent\", \"全体\"),\n            density_rank_percentile=melted_label.get(\"density_rank_percentile\"),\n        )\n        results.append(cluster_value)\n    return results\n\n\n# def _build_comments_value(\n#     comments: pd.DataFrame,\n#     arguments: pd.DataFrame,\n#     hidden_properties_map: dict[str, list[str]],\n# ):\n#     comment_dict: dict[str, dict[str, str]] = {}\n#     useful_comment_ids = set(arguments[\"comment-id\"].values)\n#     for _, row in comments.iterrows():\n#         id = row[\"comment-id\"]\n#         if id in useful_comment_ids:\n#             res = {\"comment\": row[\"comment-body\"]}\n#             should_skip = any(row[prop] in hidden_values for prop, hidden_values in hidden_properties_map.items())\n#             if should_skip:\n#                 continue\n#             comment_dict[str(id)] = res\n\n#     return comment_dict\n\n\ndef _build_translations(config):\n    languages = list(config.get(\"translation\", {}).get(\"languages\", []))\n    if len(languages) > 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        return json.loads(translations)\n    return {}\n\n\ndef _build_property_map(\n    arguments: pd.DataFrame, hidden_properties_map: dict[str, list[str]], config: dict\n) -> dict[str, dict[str, str]]:\n    property_columns = list(hidden_properties_map.keys()) + list(config[\"extraction\"][\"categories\"].keys())\n    property_map = defaultdict(dict)\n\n    # 指定された property_columns が arguments に存在するかチェック\n    missing_cols = [col for col in property_columns if col not in arguments.columns]\n    if missing_cols:\n        raise ValueError(\n            f\"指定されたカラム {missing_cols} が args.csv に存在しません。\"\n            \"設定ファイルaggregation / hidden_propertiesから該当カラムを取り除いてください。\"\n        )\n\n    for prop in property_columns:\n        for arg_id, row in arguments.iterrows():\n            # LLMによるcategory classificationがうまく行かず、NaNの場合はNoneにする\n            property_map[prop][arg_id] = row[prop] if not pd.isna(row[prop]) else None\n    return property_map"
      },
      "plan": [
        {
          "step": "extraction",
          "run": false,
          "reason": "nothing changed"
        },
        {
          "step": "embedding",
          "run": true,
          "reason": "not trace of previous run"
        },
        {
          "step": "hierarchical_clustering",
          "run": true,
          "reason": "not trace of previous run"
        },
        {
          "step": "hierarchical_initial_labelling",
          "run": true,
          "reason": "not trace of previous run"
        },
        {
          "step": "hierarchical_merge_labelling",
          "run": true,
          "reason": "not trace of previous run"
        },
        {
          "step": "hierarchical_overview",
          "run": true,
          "reason": "not trace of previous run"
        },
        {
          "step": "hierarchical_aggregation",
          "run": true,
          "reason": "not trace of previous run"
        }
      ],
      "status": "error",
      "start_time": "2025-04-15T17:13:23.913938",
      "completed_jobs": [
        {
          "step": "embedding",
          "completed": "2025-04-15T17:13:28.487694",
          "duration": 4.569754,
          "params": {
            "model": "text-embedding-3-small",
            "source_code": "import pandas as pd\nfrom tqdm import tqdm\n\nfrom services.llm import request_to_embed\n\n\ndef embedding(config):\n    model = config[\"embedding\"][\"model\"]\n\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\", usecols=[\"arg-id\", \"argument\"])\n    embeddings = []\n    batch_size = 1000\n    for i in tqdm(range(0, len(arguments), batch_size)):\n        args = arguments[\"argument\"].tolist()[i : i + batch_size]\n        embeds = request_to_embed(args, model)\n        embeddings.extend(embeds)\n    df = pd.DataFrame([{\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e} for i, e in enumerate(embeddings)])\n    df.to_pickle(path)"
          }
        },
        {
          "step": "hierarchical_clustering",
          "completed": "2025-04-15T17:14:12.007345",
          "duration": 43.516621,
          "params": {
            "cluster_nums": [
              3,
              6,
              12,
              24
            ],
            "source_code": "\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nfrom importlib import import_module\n\nimport numpy as np\nimport pandas as pd\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import KMeans\n\n\ndef hierarchical_clustering(config):\n    UMAP = import_module(\"umap\").UMAP\n\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\", usecols=[\"arg-id\", \"argument\"])\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    cluster_nums = config[\"hierarchical_clustering\"][\"cluster_nums\"]\n\n    n_samples = embeddings_array.shape[0]\n    # デフォルト設定は15\n    default_n_neighbors = 15\n\n    # テスト等サンプルが少なすぎる場合、n_neighborsの設定値を下げる\n    if n_samples <= default_n_neighbors:\n        n_neighbors = max(2, n_samples - 1)  # 最低2以上\n    else:\n        n_neighbors = default_n_neighbors\n\n    umap_model = UMAP(random_state=42, n_components=2, n_neighbors=n_neighbors)\n    # TODO 詳細エラーメッセージを加える\n    # 以下のエラーの場合、おそらく元の意見件数が少なすぎることが原因\n    # TypeError: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.\n    umap_embeds = umap_model.fit_transform(embeddings_array)\n\n    cluster_results = hierarchical_clustering_embeddings(\n        umap_embeds=umap_embeds,\n        cluster_nums=cluster_nums,\n    )\n    result_df = pd.DataFrame(\n        {\n            \"arg-id\": arguments_df[\"arg-id\"],\n            \"argument\": arguments_df[\"argument\"],\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        }\n    )\n\n    for cluster_level, final_labels in enumerate(cluster_results.values(), start=1):\n        result_df[f\"cluster-level-{cluster_level}-id\"] = [f\"{cluster_level}_{label}\" for label in final_labels]\n\n    result_df.to_csv(path, index=False)\n\n\n# def generate_cluster_count_list(min_clusters: int, max_clusters: int):\n#     cluster_counts = []\n#     current = min_clusters\n#     cluster_counts.append(current)\n\n#     if min_clusters == max_clusters:\n#         return cluster_counts\n\n#     while True:\n#         next_double = current * 2\n#         next_triple = current * 3\n\n#         if next_double >= max_clusters:\n#             if cluster_counts[-1] != max_clusters:\n#                 cluster_counts.append(max_clusters)\n#             break\n\n#         # 次の倍はまだ max_clusters に収まるが、3倍だと超える\n#         # -> (次の倍は細かすぎるので)スキップして max_clusters に飛ぶ\n#         if next_triple > max_clusters:\n#             cluster_counts.append(max_clusters)\n#             break\n\n#         cluster_counts.append(next_double)\n#         current = next_double\n\n#     return cluster_counts\n\n\ndef merge_clusters_with_hierarchy(\n    cluster_centers: np.ndarray,\n    kmeans_labels: np.ndarray,\n    umap_array: np.ndarray,\n    n_cluster_cut: int,\n):\n    Z = sch.linkage(cluster_centers, method=\"ward\")\n    cluster_labels_merged = sch.fcluster(Z, t=n_cluster_cut, criterion=\"maxclust\")\n\n    n_samples = umap_array.shape[0]\n    final_labels = np.zeros(n_samples, dtype=int)\n\n    for i in range(n_samples):\n        original_label = kmeans_labels[i]\n        final_labels[i] = cluster_labels_merged[original_label]\n\n    return final_labels\n\n\ndef hierarchical_clustering_embeddings(\n    umap_embeds,\n    cluster_nums,\n):\n    # 最大分割数でクラスタリングを実施\n    print(\"start initial clustering\")\n    initial_cluster_num = cluster_nums[-1]\n    kmeans_model = KMeans(n_clusters=initial_cluster_num, random_state=42)\n    kmeans_model.fit(umap_embeds)\n    print(\"end initial clustering\")\n\n    results = {}\n    print(\"start hierarchical clustering\")\n    cluster_nums.sort()\n    print(cluster_nums)\n    for n_cluster_cut in cluster_nums[:-1]:\n        print(\"n_cluster_cut: \", n_cluster_cut)\n        final_labels = merge_clusters_with_hierarchy(\n            cluster_centers=kmeans_model.cluster_centers_,\n            kmeans_labels=kmeans_model.labels_,\n            umap_array=umap_embeds,\n            n_cluster_cut=n_cluster_cut,\n        )\n        results[n_cluster_cut] = final_labels\n\n    results[initial_cluster_num] = kmeans_model.labels_\n    print(\"end hierarchical clustering\")\n\n    return results"
          }
        },
        {
          "step": "hierarchical_initial_labelling",
          "completed": "2025-04-15T17:15:37.115418",
          "duration": 85.104113,
          "params": {
            "sampling_num": 3,
            "workers": 1,
            "source_code": "import json\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import partial\nfrom typing import TypedDict\n\nimport pandas as pd\n\nfrom services.llm import request_to_chat_llm\n\n\nclass LabellingResult(TypedDict):\n    \"\"\"各クラスタのラベリング結果を表す型\"\"\"\n\n    cluster_id: str  # クラスタのID\n    label: str  # クラスタのラベル名\n    description: str  # クラスタの説明文\n\n\ndef hierarchical_initial_labelling(config: dict) -> None:\n    \"\"\"階層的クラスタリングの初期ラベリングを実行する\n\n    Args:\n        config: 設定情報を含む辞書\n            - output_dir: 出力ディレクトリ名\n            - hierarchical_initial_labelling: 初期ラベリングの設定\n                - sampling_num: サンプリング数\n                - prompt: LLMへのプロンプト\n                - model: 使用するLLMモデル名\n                - workers: 並列処理のワーカー数\n    \"\"\"\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_initial_labels.csv\"\n    clusters_argument_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_clusters.csv\")\n\n    cluster_id_columns = [col for col in clusters_argument_df.columns if col.startswith(\"cluster-level-\")]\n    initial_cluster_id_column = cluster_id_columns[-1]\n    sampling_num = config[\"hierarchical_initial_labelling\"][\"sampling_num\"]\n    initial_labelling_prompt = config[\"hierarchical_initial_labelling\"][\"prompt\"]\n    model = config[\"hierarchical_initial_labelling\"][\"model\"]\n    workers = config[\"hierarchical_initial_labelling\"][\"workers\"]\n\n    initial_label_df = initial_labelling(\n        initial_labelling_prompt,\n        clusters_argument_df,\n        sampling_num,\n        model,\n        workers,\n    )\n    print(\"start initial labelling\")\n    initial_clusters_argument_df = clusters_argument_df.merge(\n        initial_label_df,\n        left_on=initial_cluster_id_column,\n        right_on=\"cluster_id\",\n        how=\"left\",\n    ).rename(\n        columns={\n            \"label\": f\"{initial_cluster_id_column.replace('-id', '')}-label\",\n            \"description\": f\"{initial_cluster_id_column.replace('-id', '')}-description\",\n        }\n    )\n    print(\"end initial labelling\")\n    initial_clusters_argument_df.to_csv(path, index=False)\n\n\ndef initial_labelling(\n    prompt: str,\n    clusters_df: pd.DataFrame,\n    sampling_num: int,\n    model: str,\n    workers: int,\n) -> pd.DataFrame:\n    \"\"\"各クラスタに対して初期ラベリングを実行する\n\n    Args:\n        prompt: LLMへのプロンプト\n        clusters_df: クラスタリング結果のDataFrame\n        sampling_num: 各クラスタからサンプリングする意見の数\n        model: 使用するLLMモデル名\n        workers: 並列処理のワーカー数\n\n    Returns:\n        各クラスタのラベリング結果を含むDataFrame\n    \"\"\"\n    cluster_columns = [col for col in clusters_df.columns if col.startswith(\"cluster-level-\")]\n    initial_cluster_column = cluster_columns[-1]\n    cluster_ids = clusters_df[initial_cluster_column].unique()\n    process_func = partial(\n        process_initial_labelling,\n        df=clusters_df,\n        prompt=prompt,\n        sampling_num=sampling_num,\n        target_column=initial_cluster_column,\n        model=model,\n    )\n    with ThreadPoolExecutor(max_workers=workers) as executor:\n        results = list(executor.map(process_func, cluster_ids))\n    return pd.DataFrame(results)\n\n\ndef process_initial_labelling(\n    cluster_id: str,\n    df: pd.DataFrame,\n    prompt: str,\n    sampling_num: int,\n    target_column: str,\n    model: str,\n) -> LabellingResult:\n    \"\"\"個別のクラスタに対してラベリングを実行する\n\n    Args:\n        cluster_id: 処理対象のクラスタID\n        df: クラスタリング結果のDataFrame\n        prompt: LLMへのプロンプト\n        sampling_num: サンプリングする意見の数\n        target_column: クラスタIDが格納されている列名\n        model: 使用するLLMモデル名\n\n    Returns:\n        クラスタのラベリング結果\n    \"\"\"\n    cluster_data = df[df[target_column] == cluster_id]\n    sampling_num = min(sampling_num, len(cluster_data))\n    cluster = cluster_data.sample(sampling_num)\n    input = \"\\n\".join(cluster[\"argument\"].values)\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": input},\n    ]\n    try:\n        response = request_to_chat_llm(messages=messages, model=model, is_json=True)\n        response_json = json.loads(response)\n        return LabellingResult(\n            cluster_id=cluster_id,\n            label=response_json.get(\"label\", \"エラーでラベル名が取得できませんでした\"),\n            description=response_json.get(\"description\", \"エラーで解説が取得できませんでした\"),\n        )\n    except Exception as e:\n        print(e)\n        return LabellingResult(\n            cluster_id=cluster_id,\n            label=\"エラーでラベル名が取得できませんでした\",\n            description=\"エラーで解説が取得できませんでした\",\n        )",
            "prompt": "あなたはKJ法が得意なデータ分析者です。userのinputはグループに集まったラベルです。なぜそのラベルが一つのグループであるか解説して、それから表札をつけてください。\n出力はJSONとし、フォーマットは以下のサンプルを参考にしてください。\n\n\n# サンプルの入出力\n## 入力例\n最近、政治家が能登の復興に向けた具体的なプランを発表し、地域の未来に明るい希望が見えてきました。市民として、真摯な取り組みに感謝しています。\n災害復興支援が、選挙期間中にしっかり議論されるようになり、政治家が国民の本当のニーズに応える姿勢に期待しています。\n選挙を通じて、政治家が地域振興に全力で取り組む姿勢が伝わってきます。具体的な政策提案を目にするたび、未来への希望が膨らみます。\n\n\n## 出力例\n{{\n    \"label\": \"市民の未来を支える具体的政策への期待\",\n    \"description\": \"このクラスタには、地域の復興や被害者支援など、実際の社会課題に対して政治家が具体的かつ積極的に取り組む姿勢を支持する前向きな意見が集まっています。市民は、選挙や政策議論を通じて、現実の問題に即した支援策や復興計画が実現されることを期待し、明るい未来の構築に向けた政治の変革を応援しています。\"\n}}",
            "model": "gpt-4o"
          }
        },
        {
          "step": "hierarchical_merge_labelling",
          "completed": "2025-04-15T17:16:40.917075",
          "duration": 63.796656,
          "params": {
            "sampling_num": 3,
            "workers": 1,
            "source_code": "import json\nfrom concurrent.futures import ThreadPoolExecutor\nfrom dataclasses import dataclass\nfrom functools import partial\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom services.llm import request_to_chat_llm\n\n\n@dataclass\nclass ClusterColumns:\n    \"\"\"同一階層のクラスター関連のカラム名を管理するクラス\"\"\"\n\n    id: str\n    label: str\n    description: str\n\n    @classmethod\n    def from_id_column(cls, id_column: str) -> \"ClusterColumns\":\n        \"\"\"ID列名から関連するカラム名を生成\"\"\"\n        return cls(\n            id=id_column,\n            label=id_column.replace(\"-id\", \"-label\"),\n            description=id_column.replace(\"-id\", \"-description\"),\n        )\n\n\n@dataclass\nclass ClusterValues:\n    \"\"\"対象クラスタのlabel/descriptionを管理するクラス\"\"\"\n\n    label: str\n    description: str\n\n    def to_prompt_text(self) -> str:\n        return f\"- {self.label}: {self.description}\"\n\n\ndef hierarchical_merge_labelling(config: dict) -> None:\n    \"\"\"階層的クラスタリングの結果に対してマージラベリングを実行する\n\n    Args:\n        config: 設定情報を含む辞書\n            - output_dir: 出力ディレクトリ名\n            - hierarchical_merge_labelling: マージラベリングの設定\n                - sampling_num: サンプリング数\n                - prompt: LLMへのプロンプト\n                - model: 使用するLLMモデル名\n                - workers: 並列処理のワーカー数\n    \"\"\"\n    dataset = config[\"output_dir\"]\n    merge_path = f\"outputs/{dataset}/hierarchical_merge_labels.csv\"\n    clusters_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_initial_labels.csv\")\n\n    cluster_id_columns: list[str] = _filter_id_columns(clusters_df.columns)\n    # ボトムクラスタのラベル・説明とクラスタid付きの各argumentを入力し、各階層のクラスタラベル・説明を生成し、argumentに付けたdfを作成\n    merge_result_df = merge_labelling(\n        clusters_df=clusters_df,\n        cluster_id_columns=sorted(cluster_id_columns, reverse=True),\n        config=config,\n    )\n    # 上記のdfから各クラスタのlevel, id, label, description, valueを取得してdfを作成\n    melted_df = melt_cluster_data(merge_result_df)\n    # 上記のdfに親子関係を追加\n    parent_child_df = _build_parent_child_mapping(merge_result_df, cluster_id_columns)\n    melted_df = melted_df.merge(parent_child_df, on=[\"level\", \"id\"], how=\"left\")\n    density_df = calculate_cluster_density(melted_df, config)\n    density_df.to_csv(merge_path, index=False)\n\n\ndef _build_parent_child_mapping(df: pd.DataFrame, cluster_id_columns: list[str]):\n    \"\"\"クラスタ間の親子関係をマッピングする\n\n    Args:\n        df: クラスタリング結果のDataFrame\n        cluster_id_columns: クラスタIDのカラム名のリスト\n\n    Returns:\n        親子関係のマッピング情報を含むDataFrame\n    \"\"\"\n    results = []\n    top_cluster_column = cluster_id_columns[0]\n    top_cluster_values = df[top_cluster_column].unique()\n    for c in top_cluster_values:\n        results.append(\n            {\n                \"level\": 1,\n                \"id\": c,\n                \"parent\": \"0\",  # aggregationで追加する全体クラスタのid\n            }\n        )\n\n    for idx in range(len(cluster_id_columns) - 1):\n        current_column = cluster_id_columns[idx]\n        children_column = cluster_id_columns[idx + 1]\n        current_level = current_column.replace(\"-id\", \"\").replace(\"cluster-level-\", \"\")\n        # 現在のレベルのクラスタid\n        current_cluster_values = df[current_column].unique()\n        for current_id in current_cluster_values:\n            children_ids = df.loc[df[current_column] == current_id, children_column].unique()\n            for child_id in children_ids:\n                results.append(\n                    {\n                        \"level\": int(current_level) + 1,\n                        \"id\": child_id,\n                        \"parent\": current_id,\n                    }\n                )\n    return pd.DataFrame(results)\n\n\ndef _filter_id_columns(columns: list[str]) -> list[str]:\n    \"\"\"クラスタIDのカラム名をフィルタリングする\n\n    Args:\n        columns: 全カラム名のリスト\n\n    Returns:\n        クラスタIDのカラム名のリスト\n    \"\"\"\n    return [col for col in columns if col.startswith(\"cluster-level-\") and col.endswith(\"-id\")]\n\n\ndef melt_cluster_data(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"クラスタデータを行形式に変換する\n\n    cluster-level-n-(id|label|description) を行形式 (level, id, label, description, value) にまとめる。\n    [cluster-level-n-id, cluster-level-n-label, cluster-level-n-description] を [level, id, label, description, value(件数)] に変換する。\n\n    Args:\n        df: クラスタリング結果のDataFrame\n\n    Returns:\n        行形式に変換されたDataFrame\n    \"\"\"\n    id_columns: list[str] = _filter_id_columns(df.columns)\n    levels: set[int] = {int(col.replace(\"cluster-level-\", \"\").replace(\"-id\", \"\")) for col in id_columns}\n    all_rows: list[dict] = []\n\n    # levelごとに各クラスタの出現件数を集計・縦持ちにする\n    for level in levels:\n        cluster_columns = ClusterColumns.from_id_column(f\"cluster-level-{level}-id\")\n        # クラスタidごとの件数集計\n        level_count_df = df.groupby(cluster_columns.id).size().reset_index(name=\"value\")\n\n        level_unique_val_df = df[\n            [cluster_columns.id, cluster_columns.label, cluster_columns.description]\n        ].drop_duplicates()\n        level_unique_val_df = level_unique_val_df.merge(level_count_df, on=cluster_columns.id, how=\"left\")\n        level_unique_vals = [\n            {\n                \"level\": level,\n                \"id\": row[cluster_columns.id],\n                \"label\": row[cluster_columns.label],\n                \"description\": row[cluster_columns.description],\n                \"value\": row[\"value\"],\n            }\n            for _, row in level_unique_val_df.iterrows()\n        ]\n        all_rows.extend(level_unique_vals)\n    return pd.DataFrame(all_rows)\n\n\ndef merge_labelling(clusters_df: pd.DataFrame, cluster_id_columns: list[str], config) -> pd.DataFrame:\n    \"\"\"階層的なクラスタのマージラベリングを実行する\n\n    Args:\n        clusters_df: クラスタリング結果のDataFrame\n        cluster_id_columns: クラスタIDのカラム名のリスト\n        config: 設定情報を含む辞書\n\n    Returns:\n        マージラベリング結果を含むDataFrame\n    \"\"\"\n    for idx in tqdm(range(len(cluster_id_columns) - 1)):\n        previous_columns = ClusterColumns.from_id_column(cluster_id_columns[idx])\n        current_columns = ClusterColumns.from_id_column(cluster_id_columns[idx + 1])\n\n        process_fn = partial(\n            process_merge_labelling,\n            result_df=clusters_df,\n            current_columns=current_columns,\n            previous_columns=previous_columns,\n            config=config,\n        )\n\n        current_cluster_ids = sorted(clusters_df[current_columns.id].unique())\n        with ThreadPoolExecutor(max_workers=config[\"hierarchical_merge_labelling\"][\"workers\"]) as executor:\n            responses = list(\n                tqdm(\n                    executor.map(process_fn, current_cluster_ids),\n                    total=len(current_cluster_ids),\n                )\n            )\n\n        current_result_df = pd.DataFrame(responses)\n        clusters_df = clusters_df.merge(current_result_df, on=[current_columns.id])\n    return clusters_df\n\n\ndef process_merge_labelling(\n    target_cluster_id: str,\n    result_df: pd.DataFrame,\n    current_columns: ClusterColumns,\n    previous_columns: ClusterColumns,\n    config,\n):\n    \"\"\"個別のクラスタに対してマージラベリングを実行する\n\n    Args:\n        target_cluster_id: 処理対象のクラスタID\n        result_df: クラスタリング結果のDataFrame\n        current_columns: 現在のレベルのカラム情報\n        previous_columns: 前のレベルのカラム情報\n        config: 設定情報を含む辞書\n\n    Returns:\n        マージラベリング結果を含む辞書\n    \"\"\"\n\n    def filter_previous_values(df: pd.DataFrame, previous_columns: ClusterColumns) -> list[ClusterValues]:\n        \"\"\"前のレベルのクラスタ情報を取得する\"\"\"\n        previous_records = df[df[current_columns.id] == target_cluster_id][\n            [previous_columns.label, previous_columns.description]\n        ].drop_duplicates()\n        previous_values = [\n            ClusterValues(\n                label=row[previous_columns.label],\n                description=row[previous_columns.description],\n            )\n            for _, row in previous_records.iterrows()\n        ]\n        return previous_values\n\n    previous_values = filter_previous_values(result_df, previous_columns)\n    if len(previous_values) == 1:\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: previous_values[0].label,\n            current_columns.description: previous_values[0].description,\n        }\n    elif len(previous_values) == 0:\n        raise ValueError(f\"クラスタ {target_cluster_id} には前のレベルのクラスタが存在しません。\")\n\n    current_cluster_data = result_df[result_df[current_columns.id] == target_cluster_id]\n    sampling_num = min(\n        config[\"hierarchical_merge_labelling\"][\"sampling_num\"],\n        len(current_cluster_data),\n    )\n    sampled_data = current_cluster_data.sample(sampling_num)\n    sampled_argument_text = \"\\n\".join(sampled_data[\"argument\"].values)\n    cluster_text = \"\\n\".join([value.to_prompt_text() for value in previous_values])\n    messages = [\n        {\"role\": \"system\", \"content\": config[\"hierarchical_merge_labelling\"][\"prompt\"]},\n        {\n            \"role\": \"user\",\n            \"content\": \"クラスタラベル\\n\" + cluster_text + \"\\n\" + \"クラスタの意見\\n\" + sampled_argument_text,\n        },\n    ]\n    try:\n        response = request_to_chat_llm(\n            messages=messages,\n            model=config[\"hierarchical_merge_labelling\"][\"model\"],\n            is_json=True,\n        )\n        response_json = json.loads(response)\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: response_json.get(\"label\", \"エラーでラベル名が取得できませんでした\"),\n            current_columns.description: response_json.get(\"description\", \"エラーで解説が取得できませんでした\"),\n        }\n    except Exception as e:\n        print(f\"エラーが発生しました: {e}\")\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: \"エラーでラベル名が取得できませんでした\",\n            current_columns.description: \"エラーで解説が取得できませんでした\",\n        }\n\n\ndef calculate_cluster_density(melted_df: pd.DataFrame, config: dict):\n    \"\"\"クラスタ内の密度計算\"\"\"\n    hierarchical_cluster_df = pd.read_csv(f\"outputs/{config['output_dir']}/hierarchical_clusters.csv\")\n\n    densities = []\n    for level, c_id in zip(melted_df[\"level\"], melted_df[\"id\"], strict=False):\n        cluster_embeds = hierarchical_cluster_df[hierarchical_cluster_df[f\"cluster-level-{level}-id\"] == c_id][\n            [\"x\", \"y\"]\n        ].values\n        density = calculate_density(cluster_embeds)\n        densities.append(density)\n\n    # 密度のランクを計算\n    melted_df[\"density\"] = densities\n    melted_df[\"density_rank\"] = melted_df.groupby(\"level\")[\"density\"].rank(ascending=False, method=\"first\")\n    melted_df[\"density_rank_percentile\"] = melted_df.groupby(\"level\")[\"density_rank\"].transform(lambda x: x / len(x))\n    return melted_df\n\n\ndef calculate_density(embeds: np.ndarray):\n    \"\"\"平均距離に基づいて密度を計算\"\"\"\n    center = np.mean(embeds, axis=0)\n    distances = np.linalg.norm(embeds - center, axis=1)\n    avg_distance = np.mean(distances)\n    density = 1 / (avg_distance + 1e-10)\n    return density",
            "prompt": "分割されすぎたクラスタを統合する必要があるので、統合後の名称を考えて出力して。\n\n# 指示\n* 統合前のクラスタの名称・説明および統合後のクラスタに属するデータ点のサンプルを与えるので、これらに基づいて統合後のクラスタの名称を出力してください\n    * 統合後のクラスタ名において、統合前のクラスタ名をそのまま使うことは避けてください。\n* 出力例に記載したJSONのフォーマットに従って出力してください\n\n# サンプルの入出力\n## 入力例（クラスタラベル:説明文）\n- 地域の災害対応への批判: このクラスタは、地域における災害対応策の実施や体制に対する批判的な意見を集約したものです。住民からは、迅速かつ効果的な支援が行われていない点や、情報提供・連携の不足などに対する強い不満が表明されています。\n- 災害対応への不満: このクラスタは、災害発生時の対応全般に対する不満を示す意見をまとめたものです。救援活動の遅れや支援策の実効性に疑問を持つ声が多く、より積極的で透明性のある対応を求める意見が特徴です。\n- 地域復興の遅れ: このクラスタは、災害後の地域復興プロセスが予定通りに進んでいない点に対する懸念や不満を反映しています。再建計画や支援策の実施の遅延、そしてそれに伴う住民の生活再建への影響が強調されています。\n\n\n## 出力例\n{{\n    \"label\": \"地域再生と災害支援に対する期待と懸念\",\n    \"description\": \"このクラスタは、特定の地域における再生や災害支援策に対し、具体的な取り組みが不足しているとの意見を集約しています。市民は、選挙を通じた政策議論の中で、地域復興や被災者支援を最優先すべきだとの期待と、現行の支援策に対する改善要求を強く表明しており、より効果的な政府の対応を求める声が反映されています。\"\n}}",
            "model": "gpt-4o"
          }
        },
        {
          "step": "hierarchical_overview",
          "completed": "2025-04-15T17:16:44.540281",
          "duration": 3.617034,
          "params": {
            "source_code": "\"\"\"Create summaries for the clusters.\"\"\"\n\nimport pandas as pd\n\nfrom services.llm import request_to_chat_llm\n\n\ndef hierarchical_overview(config):\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_overview.txt\"\n\n    hierarchical_label_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_merge_labels.csv\")\n\n    prompt = config[\"hierarchical_overview\"][\"prompt\"]\n    model = config[\"hierarchical_overview\"][\"model\"]\n\n    # TODO: level1で固定にしているが、設定で変えられるようにする\n    target_level = 1\n    target_records = hierarchical_label_df[hierarchical_label_df[\"level\"] == target_level]\n    ids = target_records[\"id\"].to_list()\n    labels = target_records[\"label\"].to_list()\n    descriptions = target_records[\"description\"].to_list()\n    target_records.set_index(\"id\", inplace=True)\n\n    input = \"\"\n    for i, _ in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels[i]}\\n\\n\"\n        input += descriptions[i] + \"\\n\\n\"\n\n    messages = [{\"role\": \"user\", \"content\": prompt}, {\"role\": \"user\", \"content\": input}]\n    response = request_to_chat_llm(messages=messages, model=model)\n\n    with open(path, \"w\") as file:\n        file.write(response)",
            "prompt": "/system \n\nあなたはシンクタンクで働く専門のリサーチアシスタントです。\nチームは特定のテーマに関してパブリック・コンサルテーションを実施し、異なる選択肢のクラスターを分析し始めています。\nこれからクラスターのリストとその簡単な分析が提供されます。\nあなたの仕事は、調査結果の簡潔な要約を返すことです。要約は非常に簡潔に（最大で1段落、最大4文）まとめ、無意味な言葉を避けてください。\n出力は日本語で行ってください。",
            "model": "gpt-4o"
          }
        }
      ],
      "lock_until": "2025-04-15T17:21:44.923730",
      "current_job": "hierarchical_aggregation",
      "current_job_started": "2025-04-15T17:16:44.544314",
      "current_job_progress": null,
      "current_jop_tasks": null,
      "previously_completed_jobs": [
        {
          "step": "extraction",
          "completed": "2025-04-15T11:05:52.302187",
          "duration": 234.420417,
          "params": {
            "workers": 3,
            "limit": 200,
            "properties": [],
            "categories": {},
            "category_batch_size": 5,
            "source_code": "import concurrent.futures\nimport json\nimport logging\nimport re\n\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom services.category_classification import classify_args\nfrom services.llm import request_to_chat_llm\nfrom services.parse_json_list import parse_response\nfrom hierarchical_utils import update_progress # 前まではbroadlistening.utilsから呼び出していた。これでエラーになったらもとに戻す。\n\nCOMMA_AND_SPACE_AND_RIGHT_BRACKET = re.compile(r\",\\s*(\\])\")\n\n\ndef _validate_property_columns(property_columns: list[str], comments: pd.DataFrame) -> None:\n    if not all(property in comments.columns for property in property_columns):\n        raise ValueError(f\"Properties {property_columns} not found in comments. Columns are {comments.columns}\")\n\n\ndef extraction(config):\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/args.csv\"\n    model = config[\"extraction\"][\"model\"]\n    prompt = config[\"extraction\"][\"prompt\"]\n    workers = config[\"extraction\"][\"workers\"]\n    limit = config[\"extraction\"][\"limit\"]\n    property_columns = config[\"extraction\"][\"properties\"]\n\n    # カラム名だけを読み込み、必要なカラムが含まれているか確認する\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\", nrows=0)\n    _validate_property_columns(property_columns, comments)\n    # エラーが出なかった場合、すべての行を読み込む\n    comments = pd.read_csv(\n        f\"inputs/{config['input']}.csv\", usecols=[\"comment-id\", \"comment-body\"] + config[\"extraction\"][\"properties\"]\n    )\n    comment_ids = (comments[\"comment-id\"].values)[:limit]\n    comments.set_index(\"comment-id\", inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n\n    argument_map = {}\n    relation_rows = []\n\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i : i + workers]\n        batch_inputs = [comments.loc[id][\"comment-body\"] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n\n        for comment_id, extracted_args in zip(batch, batch_results, strict=False):\n            for j, arg in enumerate(extracted_args):\n                if arg not in argument_map:\n                    # argumentテーブルに追加\n                    arg_id = f\"A{comment_id}_{j}\"\n                    argument_map[arg] = {\n                        \"arg-id\": arg_id,\n                        \"argument\": arg,\n                    }\n                else:\n                    arg_id = argument_map[arg][\"arg-id\"]\n\n                # relationテーブルにcommentとargの関係を追加\n                relation_row = {\n                    \"arg-id\": arg_id,\n                    \"comment-id\": comment_id,\n                }\n                relation_rows.append(relation_row)\n\n        update_progress(config, incr=len(batch))\n\n    # DataFrame化\n    results = pd.DataFrame(argument_map.values())\n    relation_df = pd.DataFrame(relation_rows)\n\n    if results.empty:\n        raise RuntimeError(\"result is empty, maybe bad prompt\")\n\n    classification_categories = config[\"extraction\"][\"categories\"]\n    if classification_categories:\n        results = classify_args(results, config, workers)\n\n    results.to_csv(path, index=False)\n    # comment-idとarg-idの関係を保存\n    relation_df.to_csv(f\"outputs/{dataset}/relations.csv\", index=False)\n\n\nlogging.basicConfig(level=logging.ERROR)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures_with_index = [\n            (i, executor.submit(extract_arguments, input, prompt, model)) for i, input in enumerate(batch)\n        ]\n\n        done, not_done = concurrent.futures.wait([f for _, f in futures_with_index], timeout=30)\n        results = [[] for _ in range(len(batch))]\n\n        for _, future in futures_with_index:\n            if future in not_done and not future.cancelled():\n                future.cancel()\n\n        for i, future in futures_with_index:\n            if future in done:\n                try:\n                    result = future.result()\n                    results[i] = result\n                except Exception as e:\n                    logging.error(f\"Task {future} failed with error: {e}\")\n                    results[i] = []\n        return results\n\n\n# def extract_by_llm(input, prompt, model):\n#     messages = [\n#         {\"role\": \"system\", \"content\": prompt},\n#         {\"role\": \"user\", \"content\": input},\n#     ]\n#     response = request_to_chat_llm(messages=messages, model=model)\n#     return response\n\n\ndef extract_arguments(input, prompt, model, retries=1):\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": input},\n    ]\n    try:\n        response = request_to_chat_llm(messages=messages, model=model, is_json=False)\n        items = parse_response(response)\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        print(\"Silently giving up on trying to generate valid list.\")\n        return []",
            "prompt": "# server/broadlistening/pipeline/prompts/extraction/default.txt の修正\n\n/system\nあなたは専門的なリサーチアシスタントで、与えられたテキストから「要望」「不満」「不安」に関連する意見を抽出する役割です。\n抽出した意見は、それぞれ独立した簡潔な文にしてください。意見が複数ある場合は、すべて抽出してください。\n結果は整形されたJSON形式の文字列リストとして返してください。\n抽出する意見は必ず日本語で作成してください。\n\n/human\nAI技術の進化は目覚ましいが、雇用が奪われるのではないかと心配だし、もっと透明性を高めてほしい。規制も必要だと思う。\n\n/ai\n[\n  \"AIによって雇用が奪われるのではないかという不安がある\",\n  \"AI技術の透明性を高めてほしいという要望がある\",\n  \"AI技術に対する規制が必要だという意見がある\"\n]\n\n/human\n再生可能エネルギーへの投資は良いが、コストがかかりすぎる。もっと効率的な方法はないのか。\n\n/ai\n[\n  \"再生可能エネルギーへの投資コストが高すぎることへの不満がある\",\n  \"再生可能エネルギーのより効率的な方法を求める要望がある\"\n]\n\n/human\n特に問題点は感じていない。現状維持で良い。\n\n/ai\n[]\n\n/human\n新しい公園の計画は素晴らしいが、アクセス道路が狭いのが気になる。子供たちの安全は大丈夫だろうか。もっと広い道路を整備してほしい。\n\n/ai\n[\n  \"新しい公園へのアクセス道路が狭いことへの不満がある\",\n  \"アクセス道路での子供たちの安全に対する不安がある\",\n  \"より広いアクセス道路を整備してほしいという要望がある\"\n]\n\n/human\nサポート体制には満足しているが、もう少し迅速に対応してもらえると助かる。\n\n/ai\n[\n  \"サポートの対応速度をもう少し迅速にしてほしいという要望がある\"\n]",
            "model": "gpt-4o"
          }
        }
      ],
      "end_time": "2025-04-15T17:16:44.845151",
      "error": "KeyError: 'is_pubcom'",
      "error_stack_trace": "Traceback (most recent call last):\n  File \"C:\\Users\\U76724\\Documents\\Python\\uv\\broadlistening\\hierarchical_main.py\", line 67, in main\n    run_step(\"hierarchical_aggregation\", hierarchical_aggregation, config)\n  File \"C:\\Users\\U76724\\Documents\\Python\\uv\\broadlistening\\hierarchical_utils.py\", line 223, in run_step\n    func(config)\n  File \"C:\\Users\\U76724\\Documents\\Python\\uv\\broadlistening\\steps\\hierarchical_aggregation.py\", line 77, in hierarchical_aggregation\n    if config[\"is_pubcom\"]:\n       ~~~~~~^^^^^^^^^^^^^\nKeyError: 'is_pubcom'\n"
    },
    "is_pubcom": true,
    "embedding": {
      "model": "text-embedding-3-small",
      "source_code": "import pandas as pd\nfrom tqdm import tqdm\n\nfrom services.llm import request_to_embed\n\n\ndef embedding(config):\n    model = config[\"embedding\"][\"model\"]\n\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\", usecols=[\"arg-id\", \"argument\"])\n    embeddings = []\n    batch_size = 1000\n    for i in tqdm(range(0, len(arguments), batch_size)):\n        args = arguments[\"argument\"].tolist()[i : i + batch_size]\n        embeds = request_to_embed(args, model)\n        embeddings.extend(embeds)\n    df = pd.DataFrame([{\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e} for i, e in enumerate(embeddings)])\n    df.to_pickle(path)"
    },
    "hierarchical_initial_labelling": {
      "sampling_num": 3,
      "workers": 1,
      "source_code": "import json\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import partial\nfrom typing import TypedDict\n\nimport pandas as pd\n\nfrom services.llm import request_to_chat_llm\n\n\nclass LabellingResult(TypedDict):\n    \"\"\"各クラスタのラベリング結果を表す型\"\"\"\n\n    cluster_id: str  # クラスタのID\n    label: str  # クラスタのラベル名\n    description: str  # クラスタの説明文\n\n\ndef hierarchical_initial_labelling(config: dict) -> None:\n    \"\"\"階層的クラスタリングの初期ラベリングを実行する\n\n    Args:\n        config: 設定情報を含む辞書\n            - output_dir: 出力ディレクトリ名\n            - hierarchical_initial_labelling: 初期ラベリングの設定\n                - sampling_num: サンプリング数\n                - prompt: LLMへのプロンプト\n                - model: 使用するLLMモデル名\n                - workers: 並列処理のワーカー数\n    \"\"\"\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_initial_labels.csv\"\n    clusters_argument_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_clusters.csv\")\n\n    cluster_id_columns = [col for col in clusters_argument_df.columns if col.startswith(\"cluster-level-\")]\n    initial_cluster_id_column = cluster_id_columns[-1]\n    sampling_num = config[\"hierarchical_initial_labelling\"][\"sampling_num\"]\n    initial_labelling_prompt = config[\"hierarchical_initial_labelling\"][\"prompt\"]\n    model = config[\"hierarchical_initial_labelling\"][\"model\"]\n    workers = config[\"hierarchical_initial_labelling\"][\"workers\"]\n\n    initial_label_df = initial_labelling(\n        initial_labelling_prompt,\n        clusters_argument_df,\n        sampling_num,\n        model,\n        workers,\n    )\n    print(\"start initial labelling\")\n    initial_clusters_argument_df = clusters_argument_df.merge(\n        initial_label_df,\n        left_on=initial_cluster_id_column,\n        right_on=\"cluster_id\",\n        how=\"left\",\n    ).rename(\n        columns={\n            \"label\": f\"{initial_cluster_id_column.replace('-id', '')}-label\",\n            \"description\": f\"{initial_cluster_id_column.replace('-id', '')}-description\",\n        }\n    )\n    print(\"end initial labelling\")\n    initial_clusters_argument_df.to_csv(path, index=False)\n\n\ndef initial_labelling(\n    prompt: str,\n    clusters_df: pd.DataFrame,\n    sampling_num: int,\n    model: str,\n    workers: int,\n) -> pd.DataFrame:\n    \"\"\"各クラスタに対して初期ラベリングを実行する\n\n    Args:\n        prompt: LLMへのプロンプト\n        clusters_df: クラスタリング結果のDataFrame\n        sampling_num: 各クラスタからサンプリングする意見の数\n        model: 使用するLLMモデル名\n        workers: 並列処理のワーカー数\n\n    Returns:\n        各クラスタのラベリング結果を含むDataFrame\n    \"\"\"\n    cluster_columns = [col for col in clusters_df.columns if col.startswith(\"cluster-level-\")]\n    initial_cluster_column = cluster_columns[-1]\n    cluster_ids = clusters_df[initial_cluster_column].unique()\n    process_func = partial(\n        process_initial_labelling,\n        df=clusters_df,\n        prompt=prompt,\n        sampling_num=sampling_num,\n        target_column=initial_cluster_column,\n        model=model,\n    )\n    with ThreadPoolExecutor(max_workers=workers) as executor:\n        results = list(executor.map(process_func, cluster_ids))\n    return pd.DataFrame(results)\n\n\ndef process_initial_labelling(\n    cluster_id: str,\n    df: pd.DataFrame,\n    prompt: str,\n    sampling_num: int,\n    target_column: str,\n    model: str,\n) -> LabellingResult:\n    \"\"\"個別のクラスタに対してラベリングを実行する\n\n    Args:\n        cluster_id: 処理対象のクラスタID\n        df: クラスタリング結果のDataFrame\n        prompt: LLMへのプロンプト\n        sampling_num: サンプリングする意見の数\n        target_column: クラスタIDが格納されている列名\n        model: 使用するLLMモデル名\n\n    Returns:\n        クラスタのラベリング結果\n    \"\"\"\n    cluster_data = df[df[target_column] == cluster_id]\n    sampling_num = min(sampling_num, len(cluster_data))\n    cluster = cluster_data.sample(sampling_num)\n    input = \"\\n\".join(cluster[\"argument\"].values)\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": input},\n    ]\n    try:\n        response = request_to_chat_llm(messages=messages, model=model, is_json=True)\n        response_json = json.loads(response)\n        return LabellingResult(\n            cluster_id=cluster_id,\n            label=response_json.get(\"label\", \"エラーでラベル名が取得できませんでした\"),\n            description=response_json.get(\"description\", \"エラーで解説が取得できませんでした\"),\n        )\n    except Exception as e:\n        print(e)\n        return LabellingResult(\n            cluster_id=cluster_id,\n            label=\"エラーでラベル名が取得できませんでした\",\n            description=\"エラーで解説が取得できませんでした\",\n        )",
      "prompt": "あなたはKJ法が得意なデータ分析者です。userのinputはグループに集まったラベルです。なぜそのラベルが一つのグループであるか解説して、それから表札をつけてください。\n出力はJSONとし、フォーマットは以下のサンプルを参考にしてください。\n\n\n# サンプルの入出力\n## 入力例\n最近、政治家が能登の復興に向けた具体的なプランを発表し、地域の未来に明るい希望が見えてきました。市民として、真摯な取り組みに感謝しています。\n災害復興支援が、選挙期間中にしっかり議論されるようになり、政治家が国民の本当のニーズに応える姿勢に期待しています。\n選挙を通じて、政治家が地域振興に全力で取り組む姿勢が伝わってきます。具体的な政策提案を目にするたび、未来への希望が膨らみます。\n\n\n## 出力例\n{{\n    \"label\": \"市民の未来を支える具体的政策への期待\",\n    \"description\": \"このクラスタには、地域の復興や被害者支援など、実際の社会課題に対して政治家が具体的かつ積極的に取り組む姿勢を支持する前向きな意見が集まっています。市民は、選挙や政策議論を通じて、現実の問題に即した支援策や復興計画が実現されることを期待し、明るい未来の構築に向けた政治の変革を応援しています。\"\n}}",
      "model": "gpt-4o"
    },
    "hierarchical_merge_labelling": {
      "sampling_num": 3,
      "workers": 1,
      "source_code": "import json\nfrom concurrent.futures import ThreadPoolExecutor\nfrom dataclasses import dataclass\nfrom functools import partial\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom services.llm import request_to_chat_llm\n\n\n@dataclass\nclass ClusterColumns:\n    \"\"\"同一階層のクラスター関連のカラム名を管理するクラス\"\"\"\n\n    id: str\n    label: str\n    description: str\n\n    @classmethod\n    def from_id_column(cls, id_column: str) -> \"ClusterColumns\":\n        \"\"\"ID列名から関連するカラム名を生成\"\"\"\n        return cls(\n            id=id_column,\n            label=id_column.replace(\"-id\", \"-label\"),\n            description=id_column.replace(\"-id\", \"-description\"),\n        )\n\n\n@dataclass\nclass ClusterValues:\n    \"\"\"対象クラスタのlabel/descriptionを管理するクラス\"\"\"\n\n    label: str\n    description: str\n\n    def to_prompt_text(self) -> str:\n        return f\"- {self.label}: {self.description}\"\n\n\ndef hierarchical_merge_labelling(config: dict) -> None:\n    \"\"\"階層的クラスタリングの結果に対してマージラベリングを実行する\n\n    Args:\n        config: 設定情報を含む辞書\n            - output_dir: 出力ディレクトリ名\n            - hierarchical_merge_labelling: マージラベリングの設定\n                - sampling_num: サンプリング数\n                - prompt: LLMへのプロンプト\n                - model: 使用するLLMモデル名\n                - workers: 並列処理のワーカー数\n    \"\"\"\n    dataset = config[\"output_dir\"]\n    merge_path = f\"outputs/{dataset}/hierarchical_merge_labels.csv\"\n    clusters_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_initial_labels.csv\")\n\n    cluster_id_columns: list[str] = _filter_id_columns(clusters_df.columns)\n    # ボトムクラスタのラベル・説明とクラスタid付きの各argumentを入力し、各階層のクラスタラベル・説明を生成し、argumentに付けたdfを作成\n    merge_result_df = merge_labelling(\n        clusters_df=clusters_df,\n        cluster_id_columns=sorted(cluster_id_columns, reverse=True),\n        config=config,\n    )\n    # 上記のdfから各クラスタのlevel, id, label, description, valueを取得してdfを作成\n    melted_df = melt_cluster_data(merge_result_df)\n    # 上記のdfに親子関係を追加\n    parent_child_df = _build_parent_child_mapping(merge_result_df, cluster_id_columns)\n    melted_df = melted_df.merge(parent_child_df, on=[\"level\", \"id\"], how=\"left\")\n    density_df = calculate_cluster_density(melted_df, config)\n    density_df.to_csv(merge_path, index=False)\n\n\ndef _build_parent_child_mapping(df: pd.DataFrame, cluster_id_columns: list[str]):\n    \"\"\"クラスタ間の親子関係をマッピングする\n\n    Args:\n        df: クラスタリング結果のDataFrame\n        cluster_id_columns: クラスタIDのカラム名のリスト\n\n    Returns:\n        親子関係のマッピング情報を含むDataFrame\n    \"\"\"\n    results = []\n    top_cluster_column = cluster_id_columns[0]\n    top_cluster_values = df[top_cluster_column].unique()\n    for c in top_cluster_values:\n        results.append(\n            {\n                \"level\": 1,\n                \"id\": c,\n                \"parent\": \"0\",  # aggregationで追加する全体クラスタのid\n            }\n        )\n\n    for idx in range(len(cluster_id_columns) - 1):\n        current_column = cluster_id_columns[idx]\n        children_column = cluster_id_columns[idx + 1]\n        current_level = current_column.replace(\"-id\", \"\").replace(\"cluster-level-\", \"\")\n        # 現在のレベルのクラスタid\n        current_cluster_values = df[current_column].unique()\n        for current_id in current_cluster_values:\n            children_ids = df.loc[df[current_column] == current_id, children_column].unique()\n            for child_id in children_ids:\n                results.append(\n                    {\n                        \"level\": int(current_level) + 1,\n                        \"id\": child_id,\n                        \"parent\": current_id,\n                    }\n                )\n    return pd.DataFrame(results)\n\n\ndef _filter_id_columns(columns: list[str]) -> list[str]:\n    \"\"\"クラスタIDのカラム名をフィルタリングする\n\n    Args:\n        columns: 全カラム名のリスト\n\n    Returns:\n        クラスタIDのカラム名のリスト\n    \"\"\"\n    return [col for col in columns if col.startswith(\"cluster-level-\") and col.endswith(\"-id\")]\n\n\ndef melt_cluster_data(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"クラスタデータを行形式に変換する\n\n    cluster-level-n-(id|label|description) を行形式 (level, id, label, description, value) にまとめる。\n    [cluster-level-n-id, cluster-level-n-label, cluster-level-n-description] を [level, id, label, description, value(件数)] に変換する。\n\n    Args:\n        df: クラスタリング結果のDataFrame\n\n    Returns:\n        行形式に変換されたDataFrame\n    \"\"\"\n    id_columns: list[str] = _filter_id_columns(df.columns)\n    levels: set[int] = {int(col.replace(\"cluster-level-\", \"\").replace(\"-id\", \"\")) for col in id_columns}\n    all_rows: list[dict] = []\n\n    # levelごとに各クラスタの出現件数を集計・縦持ちにする\n    for level in levels:\n        cluster_columns = ClusterColumns.from_id_column(f\"cluster-level-{level}-id\")\n        # クラスタidごとの件数集計\n        level_count_df = df.groupby(cluster_columns.id).size().reset_index(name=\"value\")\n\n        level_unique_val_df = df[\n            [cluster_columns.id, cluster_columns.label, cluster_columns.description]\n        ].drop_duplicates()\n        level_unique_val_df = level_unique_val_df.merge(level_count_df, on=cluster_columns.id, how=\"left\")\n        level_unique_vals = [\n            {\n                \"level\": level,\n                \"id\": row[cluster_columns.id],\n                \"label\": row[cluster_columns.label],\n                \"description\": row[cluster_columns.description],\n                \"value\": row[\"value\"],\n            }\n            for _, row in level_unique_val_df.iterrows()\n        ]\n        all_rows.extend(level_unique_vals)\n    return pd.DataFrame(all_rows)\n\n\ndef merge_labelling(clusters_df: pd.DataFrame, cluster_id_columns: list[str], config) -> pd.DataFrame:\n    \"\"\"階層的なクラスタのマージラベリングを実行する\n\n    Args:\n        clusters_df: クラスタリング結果のDataFrame\n        cluster_id_columns: クラスタIDのカラム名のリスト\n        config: 設定情報を含む辞書\n\n    Returns:\n        マージラベリング結果を含むDataFrame\n    \"\"\"\n    for idx in tqdm(range(len(cluster_id_columns) - 1)):\n        previous_columns = ClusterColumns.from_id_column(cluster_id_columns[idx])\n        current_columns = ClusterColumns.from_id_column(cluster_id_columns[idx + 1])\n\n        process_fn = partial(\n            process_merge_labelling,\n            result_df=clusters_df,\n            current_columns=current_columns,\n            previous_columns=previous_columns,\n            config=config,\n        )\n\n        current_cluster_ids = sorted(clusters_df[current_columns.id].unique())\n        with ThreadPoolExecutor(max_workers=config[\"hierarchical_merge_labelling\"][\"workers\"]) as executor:\n            responses = list(\n                tqdm(\n                    executor.map(process_fn, current_cluster_ids),\n                    total=len(current_cluster_ids),\n                )\n            )\n\n        current_result_df = pd.DataFrame(responses)\n        clusters_df = clusters_df.merge(current_result_df, on=[current_columns.id])\n    return clusters_df\n\n\ndef process_merge_labelling(\n    target_cluster_id: str,\n    result_df: pd.DataFrame,\n    current_columns: ClusterColumns,\n    previous_columns: ClusterColumns,\n    config,\n):\n    \"\"\"個別のクラスタに対してマージラベリングを実行する\n\n    Args:\n        target_cluster_id: 処理対象のクラスタID\n        result_df: クラスタリング結果のDataFrame\n        current_columns: 現在のレベルのカラム情報\n        previous_columns: 前のレベルのカラム情報\n        config: 設定情報を含む辞書\n\n    Returns:\n        マージラベリング結果を含む辞書\n    \"\"\"\n\n    def filter_previous_values(df: pd.DataFrame, previous_columns: ClusterColumns) -> list[ClusterValues]:\n        \"\"\"前のレベルのクラスタ情報を取得する\"\"\"\n        previous_records = df[df[current_columns.id] == target_cluster_id][\n            [previous_columns.label, previous_columns.description]\n        ].drop_duplicates()\n        previous_values = [\n            ClusterValues(\n                label=row[previous_columns.label],\n                description=row[previous_columns.description],\n            )\n            for _, row in previous_records.iterrows()\n        ]\n        return previous_values\n\n    previous_values = filter_previous_values(result_df, previous_columns)\n    if len(previous_values) == 1:\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: previous_values[0].label,\n            current_columns.description: previous_values[0].description,\n        }\n    elif len(previous_values) == 0:\n        raise ValueError(f\"クラスタ {target_cluster_id} には前のレベルのクラスタが存在しません。\")\n\n    current_cluster_data = result_df[result_df[current_columns.id] == target_cluster_id]\n    sampling_num = min(\n        config[\"hierarchical_merge_labelling\"][\"sampling_num\"],\n        len(current_cluster_data),\n    )\n    sampled_data = current_cluster_data.sample(sampling_num)\n    sampled_argument_text = \"\\n\".join(sampled_data[\"argument\"].values)\n    cluster_text = \"\\n\".join([value.to_prompt_text() for value in previous_values])\n    messages = [\n        {\"role\": \"system\", \"content\": config[\"hierarchical_merge_labelling\"][\"prompt\"]},\n        {\n            \"role\": \"user\",\n            \"content\": \"クラスタラベル\\n\" + cluster_text + \"\\n\" + \"クラスタの意見\\n\" + sampled_argument_text,\n        },\n    ]\n    try:\n        response = request_to_chat_llm(\n            messages=messages,\n            model=config[\"hierarchical_merge_labelling\"][\"model\"],\n            is_json=True,\n        )\n        response_json = json.loads(response)\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: response_json.get(\"label\", \"エラーでラベル名が取得できませんでした\"),\n            current_columns.description: response_json.get(\"description\", \"エラーで解説が取得できませんでした\"),\n        }\n    except Exception as e:\n        print(f\"エラーが発生しました: {e}\")\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: \"エラーでラベル名が取得できませんでした\",\n            current_columns.description: \"エラーで解説が取得できませんでした\",\n        }\n\n\ndef calculate_cluster_density(melted_df: pd.DataFrame, config: dict):\n    \"\"\"クラスタ内の密度計算\"\"\"\n    hierarchical_cluster_df = pd.read_csv(f\"outputs/{config['output_dir']}/hierarchical_clusters.csv\")\n\n    densities = []\n    for level, c_id in zip(melted_df[\"level\"], melted_df[\"id\"], strict=False):\n        cluster_embeds = hierarchical_cluster_df[hierarchical_cluster_df[f\"cluster-level-{level}-id\"] == c_id][\n            [\"x\", \"y\"]\n        ].values\n        density = calculate_density(cluster_embeds)\n        densities.append(density)\n\n    # 密度のランクを計算\n    melted_df[\"density\"] = densities\n    melted_df[\"density_rank\"] = melted_df.groupby(\"level\")[\"density\"].rank(ascending=False, method=\"first\")\n    melted_df[\"density_rank_percentile\"] = melted_df.groupby(\"level\")[\"density_rank\"].transform(lambda x: x / len(x))\n    return melted_df\n\n\ndef calculate_density(embeds: np.ndarray):\n    \"\"\"平均距離に基づいて密度を計算\"\"\"\n    center = np.mean(embeds, axis=0)\n    distances = np.linalg.norm(embeds - center, axis=1)\n    avg_distance = np.mean(distances)\n    density = 1 / (avg_distance + 1e-10)\n    return density",
      "prompt": "分割されすぎたクラスタを統合する必要があるので、統合後の名称を考えて出力して。\n\n# 指示\n* 統合前のクラスタの名称・説明および統合後のクラスタに属するデータ点のサンプルを与えるので、これらに基づいて統合後のクラスタの名称を出力してください\n    * 統合後のクラスタ名において、統合前のクラスタ名をそのまま使うことは避けてください。\n* 出力例に記載したJSONのフォーマットに従って出力してください\n\n# サンプルの入出力\n## 入力例（クラスタラベル:説明文）\n- 地域の災害対応への批判: このクラスタは、地域における災害対応策の実施や体制に対する批判的な意見を集約したものです。住民からは、迅速かつ効果的な支援が行われていない点や、情報提供・連携の不足などに対する強い不満が表明されています。\n- 災害対応への不満: このクラスタは、災害発生時の対応全般に対する不満を示す意見をまとめたものです。救援活動の遅れや支援策の実効性に疑問を持つ声が多く、より積極的で透明性のある対応を求める意見が特徴です。\n- 地域復興の遅れ: このクラスタは、災害後の地域復興プロセスが予定通りに進んでいない点に対する懸念や不満を反映しています。再建計画や支援策の実施の遅延、そしてそれに伴う住民の生活再建への影響が強調されています。\n\n\n## 出力例\n{{\n    \"label\": \"地域再生と災害支援に対する期待と懸念\",\n    \"description\": \"このクラスタは、特定の地域における再生や災害支援策に対し、具体的な取り組みが不足しているとの意見を集約しています。市民は、選挙を通じた政策議論の中で、地域復興や被災者支援を最優先すべきだとの期待と、現行の支援策に対する改善要求を強く表明しており、より効果的な政府の対応を求める声が反映されています。\"\n}}",
      "model": "gpt-4o"
    },
    "hierarchical_overview": {
      "source_code": "\"\"\"Create summaries for the clusters.\"\"\"\n\nimport pandas as pd\n\nfrom services.llm import request_to_chat_llm\n\n\ndef hierarchical_overview(config):\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_overview.txt\"\n\n    hierarchical_label_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_merge_labels.csv\")\n\n    prompt = config[\"hierarchical_overview\"][\"prompt\"]\n    model = config[\"hierarchical_overview\"][\"model\"]\n\n    # TODO: level1で固定にしているが、設定で変えられるようにする\n    target_level = 1\n    target_records = hierarchical_label_df[hierarchical_label_df[\"level\"] == target_level]\n    ids = target_records[\"id\"].to_list()\n    labels = target_records[\"label\"].to_list()\n    descriptions = target_records[\"description\"].to_list()\n    target_records.set_index(\"id\", inplace=True)\n\n    input = \"\"\n    for i, _ in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels[i]}\\n\\n\"\n        input += descriptions[i] + \"\\n\\n\"\n\n    messages = [{\"role\": \"user\", \"content\": prompt}, {\"role\": \"user\", \"content\": input}]\n    response = request_to_chat_llm(messages=messages, model=model)\n\n    with open(path, \"w\") as file:\n        file.write(response)",
      "prompt": "/system \n\nあなたはシンクタンクで働く専門のリサーチアシスタントです。\nチームは特定のテーマに関してパブリック・コンサルテーションを実施し、異なる選択肢のクラスターを分析し始めています。\nこれからクラスターのリストとその簡単な分析が提供されます。\nあなたの仕事は、調査結果の簡潔な要約を返すことです。要約は非常に簡潔に（最大で1段落、最大4文）まとめ、無意味な言葉を避けてください。\n出力は日本語で行ってください。",
      "model": "gpt-4o"
    },
    "hierarchical_aggregation": {
      "sampling_num": 5000,
      "hidden_properties": {},
      "source_code": "\"\"\"Generate a convenient JSON output file.\"\"\"\n\nimport json\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import TypedDict\n\nimport pandas as pd\n\nROOT_DIR = Path(__file__).parent.parent.parent.parent\nCONFIG_DIR = ROOT_DIR / \"scatter\" / \"pipeline\" / \"configs\"\n\n\nclass Argument(TypedDict):\n    arg_id: str\n    argument: str\n    comment_id: str\n    x: float\n    y: float\n    p: float\n    cluster_ids: list[str]\n\n\nclass Cluster(TypedDict):\n    level: int\n    id: str\n    label: str\n    takeaway: str\n    value: int\n    parent: str\n    density_rank_percentile: float | None\n\n\ndef hierarchical_aggregation(config):\n    path = f\"outputs/{config['output_dir']}/hierarchical_result.json\"\n    results = {\n        \"arguments\": [],\n        \"clusters\": [],\n        \"comments\": {},\n        \"propertyMap\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index(\"arg-id\", inplace=True)\n    arg_num = len(arguments)\n    relation_df = pd.read_csv(f\"outputs/{config['output_dir']}/relations.csv\")\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/hierarchical_clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/hierarchical_merge_labels.csv\")\n\n    hidden_properties_map: dict[str, list[str]] = config[\"hierarchical_aggregation\"][\"hidden_properties\"]\n\n    results[\"arguments\"] = _build_arguments(clusters)\n    results[\"clusters\"] = _build_cluster_value(labels, arg_num)\n    # NOTE: 属性に応じたコメントフィルタ機能が実装されておらず、全てのコメントが含まれてしまうので、コメントアウト\n    # results[\"comments\"] = _build_comments_value(\n    #     comments, arguments, hidden_properties_map\n    # )\n    results[\"comment_num\"] = len(comments)\n    results[\"translations\"] = _build_translations(config)\n    # 属性情報のカラムは、元データに対して指定したカラムとclassificationするカテゴリを合わせたもの\n    results[\"propertyMap\"] = _build_property_map(arguments, hidden_properties_map, config)\n\n    with open(f\"outputs/{config['output_dir']}/hierarchical_overview.txt\") as f:\n        overview = f.read()\n    print(\"overview\")\n    print(overview)\n    results[\"overview\"] = overview\n\n    with open(path, \"w\") as file:\n        json.dump(results, file, indent=2, ensure_ascii=False)\n    # TODO: サンプリングロジックを実装したいが、現状は全件抽出\n    create_custom_intro(config)\n    if config[\"is_pubcom\"]:\n        add_original_comments(labels, arguments, relation_df, clusters, config)\n\n\ndef create_custom_intro(config):\n    dataset = config[\"output_dir\"]\n    args_path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    result_path = f\"outputs/{dataset}/hierarchical_result.json\"\n\n    input_count = len(comments)\n    args_count = len(pd.read_csv(args_path))\n    processed_num = min(input_count, config[\"extraction\"][\"limit\"])\n\n    print(f\"Input count: {input_count}\")\n    print(f\"Args count: {args_count}\")\n\n    base_custom_intro = \"\"\"{intro}\n分析対象となったデータの件数は{processed_num}件で、これらのデータに対してOpenAI APIを用いて{args_count}件の意見（議論）を抽出し、クラスタリングを行った。\n\"\"\"\n\n    intro = config[\"intro\"]\n    custom_intro = base_custom_intro.format(intro=intro, processed_num=processed_num, args_count=args_count)\n\n    with open(result_path) as f:\n        result = json.load(f)\n    result[\"config\"][\"intro\"] = custom_intro\n    with open(result_path, \"w\") as f:\n        json.dump(result, f, indent=2, ensure_ascii=False)\n\n\ndef add_original_comments(labels, arguments, relation_df, clusters, config):\n    # 大カテゴリ（cluster-level-1）に該当するラベルだけ抽出\n    labels_lv1 = labels[labels[\"level\"] == 1][[\"id\", \"label\"]].rename(\n        columns={\"id\": \"cluster-level-1-id\", \"label\": \"category_label\"}\n    )\n\n    # arguments と clusters をマージ（カテゴリ情報付与）\n    merged = arguments.merge(clusters[[\"arg-id\", \"cluster-level-1-id\"]], on=\"arg-id\").merge(\n        labels_lv1, on=\"cluster-level-1-id\", how=\"left\"\n    )\n\n    # relation_df と結合\n    merged = merged.merge(relation_df, on=\"arg-id\", how=\"left\")\n\n    # 元コメント取得\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    comments[\"comment-id\"] = comments[\"comment-id\"].astype(str)\n    merged[\"comment-id\"] = merged[\"comment-id\"].astype(str)\n\n    # 元コメント本文などとマージ\n    final_df = merged.merge(comments, on=\"comment-id\", how=\"left\")\n\n    # 必要カラムのみ整形\n    final_cols = [\"comment-id\", \"comment-body\", \"arg-id\", \"argument\", \"cluster-level-1-id\", \"category_label\"]\n    for col in [\"source\", \"url\"]:\n        if col in comments.columns:\n            final_cols.append(col)\n\n    final_df = final_df[final_cols]\n    final_df = final_df.rename(\n        columns={\n            \"cluster-level-1-id\": \"category_id\",\n            \"category_label\": \"category\",\n            \"arg-id\": \"arg_id\",\n            \"argument\": \"argument\",\n            \"comment-body\": \"original-comment\",\n        }\n    )\n\n    # 保存\n    final_df.to_csv(f\"outputs/{config['output_dir']}/final_result_with_comments.csv\", index=False)\n\n\ndef _build_arguments(clusters: pd.DataFrame) -> list[Argument]:\n    cluster_columns = [col for col in clusters.columns if col.startswith(\"cluster-level-\") and \"id\" in col]\n\n    arguments: list[Argument] = []\n    for _, row in clusters.iterrows():\n        cluster_ids = [\"0\"]\n        for cluster_column in cluster_columns:\n            cluster_ids.append(row[cluster_column])\n        argument: Argument = {\n            \"arg_id\": row[\"arg-id\"],\n            \"argument\": row[\"argument\"],\n            \"x\": row[\"x\"],\n            \"y\": row[\"y\"],\n            \"p\": 0,  # NOTE: 一旦全部0でいれる\n            \"cluster_ids\": cluster_ids,\n        }\n        arguments.append(argument)\n    return arguments\n\n\ndef _build_cluster_value(melted_labels: pd.DataFrame, total_num: int) -> list[Cluster]:\n    results: list[Cluster] = [\n        Cluster(\n            level=0,\n            id=\"0\",\n            label=\"全体\",\n            takeaway=\"\",\n            value=total_num,\n            parent=\"\",\n            density_rank_percentile=0,\n        )\n    ]\n\n    for _, melted_label in melted_labels.iterrows():\n        cluster_value = Cluster(\n            level=melted_label[\"level\"],\n            id=melted_label[\"id\"],\n            label=melted_label[\"label\"],\n            takeaway=melted_label[\"description\"],\n            value=melted_label[\"value\"],\n            parent=melted_label.get(\"parent\", \"全体\"),\n            density_rank_percentile=melted_label.get(\"density_rank_percentile\"),\n        )\n        results.append(cluster_value)\n    return results\n\n\n# def _build_comments_value(\n#     comments: pd.DataFrame,\n#     arguments: pd.DataFrame,\n#     hidden_properties_map: dict[str, list[str]],\n# ):\n#     comment_dict: dict[str, dict[str, str]] = {}\n#     useful_comment_ids = set(arguments[\"comment-id\"].values)\n#     for _, row in comments.iterrows():\n#         id = row[\"comment-id\"]\n#         if id in useful_comment_ids:\n#             res = {\"comment\": row[\"comment-body\"]}\n#             should_skip = any(row[prop] in hidden_values for prop, hidden_values in hidden_properties_map.items())\n#             if should_skip:\n#                 continue\n#             comment_dict[str(id)] = res\n\n#     return comment_dict\n\n\ndef _build_translations(config):\n    languages = list(config.get(\"translation\", {}).get(\"languages\", []))\n    if len(languages) > 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        return json.loads(translations)\n    return {}\n\n\ndef _build_property_map(\n    arguments: pd.DataFrame, hidden_properties_map: dict[str, list[str]], config: dict\n) -> dict[str, dict[str, str]]:\n    property_columns = list(hidden_properties_map.keys()) + list(config[\"extraction\"][\"categories\"].keys())\n    property_map = defaultdict(dict)\n\n    # 指定された property_columns が arguments に存在するかチェック\n    missing_cols = [col for col in property_columns if col not in arguments.columns]\n    if missing_cols:\n        raise ValueError(\n            f\"指定されたカラム {missing_cols} が args.csv に存在しません。\"\n            \"設定ファイルaggregation / hidden_propertiesから該当カラムを取り除いてください。\"\n        )\n\n    for prop in property_columns:\n        for arg_id, row in arguments.iterrows():\n            # LLMによるcategory classificationがうまく行かず、NaNの場合はNoneにする\n            property_map[prop][arg_id] = row[prop] if not pd.isna(row[prop]) else None\n    return property_map"
    },
    "plan": [
      {
        "step": "extraction",
        "run": false,
        "reason": "nothing changed"
      },
      {
        "step": "embedding",
        "run": false,
        "reason": "nothing changed"
      },
      {
        "step": "hierarchical_clustering",
        "run": false,
        "reason": "nothing changed"
      },
      {
        "step": "hierarchical_initial_labelling",
        "run": false,
        "reason": "nothing changed"
      },
      {
        "step": "hierarchical_merge_labelling",
        "run": false,
        "reason": "nothing changed"
      },
      {
        "step": "hierarchical_overview",
        "run": false,
        "reason": "nothing changed"
      },
      {
        "step": "hierarchical_aggregation",
        "run": true,
        "reason": "not trace of previous run"
      }
    ],
    "status": "running",
    "start_time": "2025-04-17T10:05:59.931675",
    "completed_jobs": [],
    "lock_until": "2025-04-17T10:10:59.936668",
    "current_job": "hierarchical_aggregation",
    "current_job_started": "2025-04-17T10:05:59.936668"
  },
  "comment_num": 342
}